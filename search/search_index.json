{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#sk-transformers","title":"sk-transformers","text":"<p>A collection of various pandas &amp; scikit-learn compatible transformers for all kinds of preprocessing and feature engineering steps \ud83d\udee0</p> <p>            </p>"},{"location":"#introduction","title":"Introduction","text":"<p>Every tabular data is different. Every column needs to be treated differently. Pandas is already great! And scikit-learn has a nice collection of dataset transformers. But the possibilities of data transformation are infinite. This project tries to provide a brought collection of data transformers that can be easily used together with scikit-learn - either in a pipeline or just on its own. See the usage chapter for some examples.</p> <p>The idea is simple. It is like a well-equipped toolbox \ud83e\uddf0: You always find the tool you need and sometimes you get inspired by seeing a tool you did not know before. Please feel free to contribute your tools and ideas.</p> <p>Check out some examples in the Jupyter notebook. </p>"},{"location":"#installation","title":"Installation","text":"<p>If you are using pip, you can install the package with the following command: <pre><code>pip install sk-transformers\n</code></pre></p> <p>If you are using Poetry, you can install the package with the following command: <pre><code>poetry add sk-transformers\n</code></pre></p>"},{"location":"#installing-dependencies","title":"installing dependencies","text":"<p>With pip: <pre><code>pip install -r requirements.txt\n</code></pre></p> <p>With Poetry: <pre><code>poetry install\n</code></pre></p>"},{"location":"#available-transformers","title":"Available transformers","text":"Module Transformer Description     <code>Datetime transformer</code> <code>DateColumnsTransformer</code> Splits a date column into multiple columns.   <code>Datetime transformer</code> <code>DurationCalculatorTransformer</code> Calculates the duration between to given dates.   <code>Encoder transformer</code> <code>MeanEncoderTransformer</code> Scikit-learn API for the feature-engine MeanEncoder.   <code>Generic transformer</code> <code>AggregateTransformer</code> This transformer uses Pandas groupby method and aggregate to apply function on a column grouped by another column.   <code>Generic transformer</code> <code>AllowedValuesTransformer</code> This transformer replaces values that are not in a list with another value.   <code>Generic transformer</code> <code>ColumnDropperTransformer</code> Drops columns from a dataframe using Pandas drop method.   <code>Generic transformer</code> <code>ColumnEvalTransformer</code> Provides the possibility to use Pandas methods on columns.   <code>Generic transformer</code> <code>DtypeTransformer</code> Transformer that converts a column to a different dtype.   <code>Generic transformer</code> <code>FunctionsTransformer</code> This transformer is a plain wrapper around the sklearn.preprocessing.FunctionTransformer.   <code>Generic transformer</code> <code>LeftJoinTransformer</code> Uses Pandas merge function to perform a left-join based on the column of a dataframe and the index of another dataframe. The right dataframe is essentially a lookup table.   <code>Generic transformer</code> <code>MapTransformer</code> This transformer iterates over all columns in the <code>features</code> list and applies the given callback to the column. For this it uses the <code>pandas.Series.map</code> method.   <code>Generic transformer</code> <code>NaNTransformer</code> Replace NaN values with a specified value. Internally Pandas fillna method is used.   <code>Generic transformer</code> <code>QueryTransformer</code> Applies a list of queries to a dataframe. If it operates on a dataset used for supervised learning this transformer should be applied on the dataframe containing <code>X</code> and <code>y</code>.   <code>Generic transformer</code> <code>ValueIndicatorTransformer</code> Adds a column to a dataframe indicating if a value is equal to a specified value.   <code>Generic transformer</code> <code>ValueReplacerTransformer</code> Uses Pandas replace method to replace values in a column.   <code>Number transformer</code> <code>MathExpressionTransformer</code> Applies an operation to a column and a given value or column. The operation can be any operation from the <code>numpy</code> or <code>operator</code> package.   <code>Number transformer</code> <code>GeoDistanceTransformer</code> Calculates the distance in kilometers between two places on the earth using the latitudes and longitudes.   <code>String transformer</code> <code>EmailTransformer</code> Transforms an email address into multiple features.   <code>String transformer</code> <code>IPAddressEncoderTransformer</code> Encodes IPv4 and IPv6 strings addresses to a float representation.   <code>String transformer</code> <code>PhoneTransformer</code> Transforms a phone number into multiple features.   <code>String transformer</code> <code>StringSimilarityTransformer</code> Calculates the similarity between two strings using the <code>gestalt pattern matching</code> algorithm from the <code>SequenceMatcher</code> class.   <code>String transformer</code> <code>StringSlicerTransformer</code> Slices all entries of specified string features using the slice() function.   <code>String transformer</code> <code>StringSplitterTransformer</code> Splits a string column into multiple columns based on the occurrence of a character.   <code>String transformer</code> <code>StringCombinationTransformer</code> Contatenates two string columns after ordering them alphabetically first."},{"location":"#usage","title":"Usage","text":"<p>Let's assume you want to use some method from [NumPy's mathematical functions, to sum up the values of column <code>foo</code> and column <code>bar</code>. You could use the <code>MathExpressionTransformer</code>. <pre><code>import pandas as pd\nfrom sk_transformers import MathExpressionTransformer\n\nX = pd.DataFrame({\"foo\": [1, 2, 3], \"bar\": [4, 5, 6]})\ntransformer = MathExpressionTransformer([(\"foo\", \"np.sum\", \"bar\", {\"axis\": 0})])\ntransformer.fit_transform(X).to_numpy()\n</code></pre> <pre><code>array([[1, 4, 5],\n       [2, 5, 7],\n       [3, 6, 9]])\n</code></pre> Even if we only pass one tuple to the transformer - in this example. Like with most other transformers the idea is to simplify preprocessing by giving the possibility to operate on multiple columns at the same time. In this case, the <code>MathExpressionTransformer</code> has created an extra column with the name <code>foo_sum_bar</code>.</p> <p>In the next example, we additionally add the <code>MapTransformer</code>. Together with scikit-learn's pipelines it would look like this: <pre><code>import pandas as pd\nfrom sk_transformers import MathExpressionTransformer\nfrom sk_transformers import MapTransformer\nfrom sklearn.pipeline import Pipeline\n\nX = pd.DataFrame({\"foo\": [1, 2, 3], \"bar\": [4, 5, 6]})\nmap_step = MapTransformer([(\"foo\", lambda x: x + 100)])\nsum_step = MathExpressionTransformer([(\"foo\", \"np.sum\", \"bar\", {\"axis\": 0})])\npipeline = Pipeline([(\"map_step\", map_step), (\"sum_step\", sum_step)])\npipeline.fit_transform(X)\n</code></pre></p> <pre><code>   foo  bar  foo_sum_bar\n0  101    4          105\n1  102    5          107\n2  103    6          109\n</code></pre>"},{"location":"#contributing","title":"Contributing","text":"<p>We're all kind of in the same boat. Preprocessing/feature engineering in data science is somehow very individual - every feature is different and must be handled and processed differently. But somehow we all have the same problems: sometimes date columns have to be changed. Sometimes strings have to be formatted, sometimes durations have to be calculated, etc. There is a huge number of preprocessing possibilities but we all use the same tools.</p> <p>scikit-learns pipelines help to use formalized functions. So why not also share these so-called transformers with others? This open-source project has the goal to collect useful preprocessing pipeline steps. Let us all collect what we used for preprocessing and share it with others. This way we can all benefit from each other's work and save a lot of time. So if you have a preprocessing step that you use regularly, please feel free to contribute it to this project. The idea is that this is not only a toolbox but also an inspiration for what is possible. Maybe you have not thought about this preprocessing step before.</p> <p>Please check out the guide on how to contribute to this project.</p>"},{"location":"CONTRIBUTING/","title":"How to contribute","text":"<p>First of all, thank you \ud83d\ude4f for your interest in contributing to this project. This project is open source and is therefore open to contributions from the community. The following document describes how you can contribute to it.</p> <p>Check out this dummy example of how to create a custom transformer ready for use in a pipeline:</p>"},{"location":"CONTRIBUTING/#example-of-a-custom-transformer","title":"Example of a custom transformer","text":"<p>Your custom transformer could look something like this: <pre><code>import pandas as pd\n\nfrom sk_transformers.base_transformer import BaseTransformer\nfrom sk_transformers.utils import check_ready_to_transform\n\nclass DummyTransformer(BaseTransformer):\n    \"\"\"\n    Replaces all strings in a given column with `dummy`.\n\n    Args:\n        string_to_replace (str): The string which should be replaced by `dummy`.\n        column (str): The column to replace the strings with dummy.\n\n    Example:\n    ```python\n    import pandas as pd\n    from sklearn.pipeline import Pipeline\n\n    df = pd.DataFrame({\n        \"cocktail\": [\"French Connection\", \"Incredible Hulk\", \"Tom and Jerry\"],\n        \"bar\": [\"foo\", \"Schikaneder\", \"Futuregarden\"]\n    })\n\n    transformer = DummyTransformer(\"foo\", \"bar\")\n    transformer.fit_transform(df)\n    ```\n    ```\n                cocktail           bar\n    0  French Connection        DUMMY!\n    1    Incredible Hulk   Schikaneder\n    2      Tom and Jerry  Futuregarden\n    ```\n    \"\"\"\n    def __init__(self, string_to_replace: str, column: str) -&gt; None:\n        super().__init__()\n        self.string_to_replace = string_to_replace\n        self.column = column\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"\n         Replaces all occurrences of `string_to_replace`\n         in a certain column of X with `DUMMY!`.\n\n        Args:\n            X (pd.DataFrame): Dataframe containing the\n            column where the replacement should happen.\n\n        Returns:\n            pandas.DataFrame: Dataframe with replaced strings.\n        \"\"\"\n        X = check_ready_to_transform(self, X, self.column)\n\n        X[self.column] = X[self.column].replace(self.string_to_replace, \"DUMMY!\")\n        return X\n</code></pre> More documentation than code. You know how it is \ud83e\udd37\u200d\u2642\ufe0f. This transformer does not need an <code>fit</code> method because it does not learn anything from the data. It just replaces a string with another string.</p> <p>Now you can use it: <pre><code>import pandas as pd\nfrom sklearn.pipeline import Pipeline\n\ndf = pd.DataFrame({\n    \"cocktail\": [\"French Connection\", \"Incredible Hulk\", \"Tom and Jerry\"],\n    \"bar\": [\"foo\", \"Schikaneder\", \"Futuregarden\"]\n})\n\npipeline = Pipeline([\n    (\"dummy_transformer\", DummyTransformer(\"foo\", \"bar\")),\n])\n\npipeline.fit_transform(df).head()\n</code></pre> <pre><code>            cocktail           bar\n0  French Connection        DUMMY!\n1    Incredible Hulk   Schikaneder\n2      Tom and Jerry  Futuregarden\n</code></pre> For a non-dummy examples check out the <code>MathExpressionTransformer</code> or the <code>ValueIndicatorTransformer</code> for a simpler example.</p>"},{"location":"CONTRIBUTING/#poetry","title":"Poetry","text":"<p>We are using Poetry to manage the dependencies, for deployment, and the virtual environment. If you have not used it before please check out the documentation to get started.</p> <p>If you want to start working on the project. The first thing you have to do is: <pre><code>poetry install --with test\n</code></pre> This installs all needed dependencies for development and testing.</p>"},{"location":"CONTRIBUTING/#pre-commit-hooks","title":"Pre-commit hooks","text":"<p>We are using pre-commit to ensure a consistent code style and to avoid common mistakes. Please install the pre-commit and install the hook with: <pre><code>pre-commit install\npre-commit install --hook-type commit-msg\n</code></pre></p>"},{"location":"CONTRIBUTING/#homebrew","title":"Homebrew","text":"<p>We are using Homebrew to manage the dependencies for the development environment. Please install Homebrew and run <pre><code> brew bundle\n</code></pre> to install the dependencies. If you don't want/can't use Homebrew, you can also install the dependencies manually.</p>"},{"location":"CONTRIBUTING/#conventional-commits","title":"Conventional Commits","text":"<p>We are using Conventional Commits to ensure a consistent commit message style. Please use the following commit message format: <pre><code>&lt;type&gt;[optional scope]: &lt;description&gt;\n</code></pre> E.g.: <pre><code>feat: add a new fantastic transformer \ud83e\udd16\n</code></pre></p>"},{"location":"CONTRIBUTING/#how-to-contribute_1","title":"How to contribute","text":"<p>The following steps will give a short guide on how to contribute to this project:</p> <ul> <li>Create a personal fork of the project on GitHub.</li> <li>Clone the fork on your local machine. Your remote repo on GitHub is called <code>origin</code>.</li> <li>Add the original repository as a remote called <code>upstream</code>.</li> <li>If you created your fork a while ago be sure to pull upstream changes into your local repository.</li> <li>Create a new branch to work on! Start from <code>develop</code> if it exists, else from <code>main</code>.</li> <li>Implement/fix your feature, comment your code, and add some examples.</li> <li>Follow the code style of the project, including indentation. Black, isort, Pylint, and mypy can help you with it.</li> <li>Run all tests.</li> <li>Write or adapt tests as needed.</li> <li>Add or change the documentation as needed. Please follow the \"Google Python Style Guide\".</li> <li>Squash your commits into a single commit with git's interactive rebase. Create a new branch if necessary.</li> <li>Push your branch to your fork on GitHub, the remote <code>origin</code>.</li> <li>From your fork open a pull request in the correct branch. Target the project's <code>develop</code> branch!</li> <li>Once the pull request is approved and merged you can pull the changes from <code>upstream</code> to your local repo and delete your extra branch(es).</li> </ul>"},{"location":"API-reference/utils/","title":"Utils","text":""},{"location":"API-reference/utils/#sk_transformers.utils.check_data","title":"<code>check_data(X, y, check_nans=True)</code>","text":"<p>Checks if the data has the correct types, shapes and does not contain any missing values.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pandas.DataFrame</code>  <p>The features.</p>  required    <code>y</code>  <code>pandas.Series</code>  <p>The target variable.</p>  required    <code>check_nans</code>  <code>bool</code>  <p>Whether to check for missing values. Defaults to <code>True</code>.</p>  <code>True</code>     <p>Raises:</p>    Type Description      <code>TypeError</code>  <p>If the features are not a <code>pandas.DataFrame</code> or the target variable is not a <code>pandas.Series</code> or <code>numpy.ndarray</code>.</p>    <code>ValueError</code>  <p>If the features or target variable contain missing values.</p>    <p>Returns:</p>    Type Description      <code>None</code>  <p>None</p>     Source code in <code>src/sk_transformers/utils.py</code> <pre><code>def check_data(X: pd.DataFrame, y: pd.Series, check_nans: bool = True) -&gt; None:\n    \"\"\"Checks if the data has the correct types, shapes and does not contain\n    any missing values.\n\n    Args:\n        X (pandas.DataFrame): The features.\n        y (pandas.Series): The target variable.\n        check_nans (bool): Whether to check for missing values. Defaults to `True`.\n\n    Raises:\n        TypeError: If the features are not a `pandas.DataFrame` or the target variable is not a `pandas.Series` or `numpy.ndarray`.\n        ValueError: If the features or target variable contain missing values.\n\n    Returns:\n        None\n    \"\"\"\n    if not isinstance(X, pd.DataFrame):\n        raise TypeError(\"Features must be a pandas.DataFrame!\")\n    if not isinstance(y, pd.Series):\n        raise TypeError(\"y must be a pandas.Series!\")\n    if check_nans:\n        if X.isnull().to_numpy().any():\n            raise ValueError(\"Features must not contain NaN values!\")\n        if y.isnull().to_numpy().any():\n            raise ValueError(\"y must not contain NaN values!\")\n</code></pre>"},{"location":"API-reference/utils/#sk_transformers.utils.check_ready_to_transform","title":"<code>check_ready_to_transform(transformer, X, features, force_all_finite=True, dtype=None, return_polars=False)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>transformer</code>  <code>Any</code>  <p>The transformer that calls this function. It must be a subclass of <code>BaseEstimator</code> from scikit-learn.</p>  required    <code>X</code>  <code>pandas.DataFrame</code>  <p><code>pandas</code> dataframe. The input to check and copy or transform.</p>  required    <code>features</code>  <code>Optional[Union[str, List[str]]]</code>  <p>The features to check if they are in the dataframe.</p>  required    <code>force_all_finite</code>  <code>Union[bool, str]</code>  <p>Whether to raise an error on np.inf and np.nan in X. The possibilities are: - True: Force all values of array to be finite. - False: accepts np.inf, np.nan, pd.NA in array. - \"allow-nan\": accepts only np.nan and pd.NA values in array. Values cannot be infinite.</p>  <code>True</code>    <code>dtype</code>  <code>Optional[Union[str, List[str]]]</code>  <p>Data type of result. If None, the <code>dtype</code> of the input is preserved. If \"numeric\", <code>dtype</code> is preserved unless <code>array.dtype</code> is object. If dtype is a list of types, conversion on the first type is only performed if the dtype of the input is not in the list.</p>  <code>None</code>     <p>Raises:</p>    Type Description      <code>TypeError</code>  <p>If the input <code>transformer</code> is not a subclass of <code>BaseEstimator</code>.</p>    <code>ValueError</code>  <p>If the input <code>X</code> is not a Pandas dataframe.</p>    <code>ValueError</code>  <p>If the input is an empty Pandas dataframe.</p>    <code>ValueError</code>  <p>If the input <code>X</code> does not contain the feature.</p>    <code>ValueError</code>  <p>if the input <code>X</code> does not contain all features.</p>    <p>Returns:</p>    Type Description      <code>Union[pd.DataFrame, pl.DataFrame]</code>  <p>pandas.DataFrame: A checked copy of original dataframe.</p>     Source code in <code>src/sk_transformers/utils.py</code> <pre><code>def check_ready_to_transform(\n    transformer: Any,\n    X: pd.DataFrame,\n    features: Union[str, List[str]],\n    force_all_finite: Union[bool, str] = True,\n    dtype: Optional[Union[str, List[str]]] = None,\n    return_polars: bool = False,\n) -&gt; Union[pd.DataFrame, pl.DataFrame]:\n    \"\"\"\n    Args:\n        transformer (Any): The transformer that calls this function. It must be a subclass of `BaseEstimator` from scikit-learn.\n        X (pandas.DataFrame): `pandas` dataframe. The input to check and copy or transform.\n        features (Optional[Union[str, List[str]]]): The features to check if they are in the dataframe.\n        force_all_finite (Union[bool, str]): Whether to raise an error on np.inf and np.nan in X. The possibilities are:\n            - True: Force all values of array to be finite.\n            - False: accepts np.inf, np.nan, pd.NA in array.\n            - \"allow-nan\": accepts only np.nan and pd.NA values in array. Values cannot be infinite.\n        dtype (Optional[Union[str, List[str]]]): Data type of result. If None, the `dtype` of the input is preserved.\n            If \"numeric\", `dtype` is preserved unless `array.dtype` is object.\n            If dtype is a list of types, conversion on the first type is only performed if the dtype of the input\n            is not in the list.\n\n    Raises:\n        TypeError: If the input `transformer` is not a subclass of `BaseEstimator`.\n        ValueError: If the input `X` is not a Pandas dataframe.\n        ValueError: If the input is an empty Pandas dataframe.\n        ValueError: If the input `X` does not contain the feature.\n        ValueError: if the input `X` does not contain all features.\n\n    Returns:\n        pandas.DataFrame: A checked copy of original dataframe.\n    \"\"\"\n\n    if isinstance(features, str):\n        features = [features]\n\n    if not isinstance(X, pd.DataFrame):\n        raise ValueError(\n            f\"{transformer.__class__.__name__}: X must be a `pandas` dataframe!\"\n        )\n    if X.shape[0] == 0:\n        raise ValueError(f\"{transformer.__class__.__name__}: X must not be empty!\")\n\n    if isinstance(features, list):\n        if not all(c in X.columns for c in features):\n            not_in_df = (\n                str(list(dict.fromkeys([c for c in features if c not in X.columns])))\n                .replace(\"[\", \"\")\n                .replace(\"]\", \"\")\n                .replace(\"'\", \"`\")\n            )\n            raise ValueError(\n                f\"\"\"\n                {transformer.__class__.__name__}:\n                Not all provided `features` could be found in `X`! Following columns were not found in the dataframe: {not_in_df}.\n                \"\"\"\n            )\n\n    if issubclass(transformer.__class__, BaseEstimator) is False:\n        raise TypeError(\n            f\"\"\"\n            `transformer` from type (`{transformer.__class__.__name__}`) is not a subclass of `BaseEstimator`!\n            See https://github.com/scikit-learn-contrib/project-template/blob/master/skltemplate/_template.py#L146 for an example/template.\n            \"\"\"\n        )\n    check_is_fitted(transformer, \"fitted_\")\n\n    X_tmp = X[\n        dict.fromkeys(X[features]).keys()\n    ].copy()  # `dict.fromkeys` was chosen instead of `set` to maintain the order of the entries.\n\n    X_tmp_array = check_array(\n        X_tmp.to_numpy(),\n        dtype=dtype,\n        accept_large_sparse=False,\n        force_all_finite=force_all_finite,\n    )\n    X_tmp = pd.DataFrame(X_tmp_array, columns=X_tmp.columns, index=X_tmp.index)\n\n    for column in X_tmp.columns:\n        X_tmp[column] = X_tmp[column].astype(X[column].dtype)\n\n    non_included_features = [c for c in X.columns if c not in features]\n    if non_included_features:\n        X_tmp = pd.concat([X_tmp, X[non_included_features]], axis=1)\n\n    return pl.from_pandas(X_tmp) if return_polars else X_tmp\n</code></pre>"},{"location":"API-reference/utils/#sk_transformers.utils.prepare_categorical_data","title":"<code>prepare_categorical_data(X, categories)</code>","text":"<p>Checks for the validity of the categorical features inside the dataframe. And prepares the data for further processing by changing the <code>dtypes</code>.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pandas.DataFrame</code>  <p>The dataframe containing the categorical features.</p>  required    <code>categories</code>  <code>List[Tuple[str, int]]</code>  <p>The list of categorical features and their thresholds. If the number of unique values is greater than the threshold, the feature is not considered categorical.</p>  required     <p>Raises:</p>    Type Description      <code>TypeError</code>  <p>If the features are not a <code>pandas.DataFrame</code> or the categorical features are not a <code>List[str]</code>.</p>    <code>ValueError</code>  <p>If the categorical features are not in the dataframe.</p>    <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pandas.DataFrame: The original dataframe with the categorical features converted to <code>category</code> dtype.</p>     Source code in <code>src/sk_transformers/utils.py</code> <pre><code>def prepare_categorical_data(\n    X: pd.DataFrame, categories: List[Tuple[str, int]]\n) -&gt; pd.DataFrame:\n    \"\"\"Checks for the validity of the categorical features inside the\n    dataframe. And prepares the data for further processing by changing the\n    `dtypes`.\n\n    Args:\n        X (pandas.DataFrame): The dataframe containing the categorical features.\n        categories (List[Tuple[str, int]]): The list of categorical features and their thresholds.\n            If the number of unique values is greater than the threshold, the feature is not considered categorical.\n\n    Raises:\n        TypeError: If the features are not a `pandas.DataFrame` or the categorical features are not a `List[str]`.\n        ValueError: If the categorical features are not in the dataframe.\n\n    Returns:\n        pandas.DataFrame: The original dataframe with the categorical features converted to `category` dtype.\n    \"\"\"\n    cat_features = [f[0] for f in categories]\n\n    if not isinstance(X, pd.DataFrame):\n        raise TypeError(\"features must be a pandas.DataFrame!\")\n    if not set(set(cat_features)).issubset(set(X.columns)):\n        raise ValueError(\"cat_features must be in the dataframe!\")\n\n    for feature, threshold in categories:\n        if (str(X[feature].dtype) != \"object\") or (X[feature].nunique() &gt; threshold):\n            cat_features.remove(feature)\n            print(\n                f\"\"\"{feature} has fewer unique values than {threshold}.\n                So it will not be converted to Category dtype.\"\"\"\n            )\n\n    pd.options.mode.chained_assignment = None\n    for column in X.columns:\n        if column in cat_features:\n            X[column] = X[column].astype(\"category\").copy()\n\n    return X\n</code></pre>"},{"location":"API-reference/transformer/base_transformer/","title":"Base transformer","text":""},{"location":"API-reference/transformer/base_transformer/#sk_transformers.base_transformer.BaseTransformer","title":"<code>BaseTransformer</code>","text":"<p>         Bases: <code>BaseEstimator</code>, <code>TransformerMixin</code></p> <p>Base class for all custom transformers.</p> <p>This class inherits from BaseEstimator and TransformerMixin. Its main purpose is to provide an implementation of the <code>fit</code> method that does nothing except setting the <code>self.fitted_</code> to <code>True</code>. Since most custom transformers do not need to implement a fit method, this class can be used as a base class for all transformers not needing a <code>fit</code> method.</p>  Source code in <code>src/sk_transformers/base_transformer.py</code> <pre><code>class BaseTransformer(BaseEstimator, TransformerMixin):\n    \"\"\"Base class for all custom transformers.\n\n    This class inherits from BaseEstimator and TransformerMixin. Its\n    main purpose is to provide an implementation of the `fit` method\n    that does nothing except setting the `self.fitted_` to `True`. Since\n    most custom transformers do not need to implement a fit method, this\n    class can be used as a base class for all transformers not needing a\n    `fit` method.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        self.fitted_ = False\n\n    def fit(self, X=None, y=None):  # type: ignore\n        self.fitted_ = True\n        return self\n</code></pre>"},{"location":"API-reference/transformer/datetime_transformer/","title":"Datetime transformer","text":""},{"location":"API-reference/transformer/datetime_transformer/#sk_transformers.datetime_transformer.DateColumnsTransformer","title":"<code>DateColumnsTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>Splits a date column into multiple columns.</p> <p>Example: <pre><code>import pandas as pd\nfrom sk_transformers import DateColumnsTransformer\n\nX = pd.DataFrame({\"foo\": [\"2021-01-01\", \"2022-02-02\", \"2023-03-03\"]})\ntransformer = DateColumnsTransformer([\"foo\"])\ntransformer.fit_transform(X)\n</code></pre> <pre><code>         foo  foo_year  ...  foo_is_year_end  foo_is_weekend\n0 2021-01-01      2021  ...            False           False\n1 2022-02-02      2022  ...            False           False\n2 2023-03-03      2023  ...            False           False\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>features</code>  <code>List[str]</code>  <p>List of columns to transform.</p>  required    <code>date_format</code>  <code>str</code>  <p>Date format. Defaults to <code>%Y-%m-%d</code>.</p>  <code>'%Y-%m-%d'</code>    <code>errors</code>  <code>str</code>  <p>How to handle errors in <code>pd.to_datetime</code>. Defaults to <code>raise</code>. available values: <code>ignore</code>, <code>raise</code>, <code>coerce</code>. If <code>raise</code>, then invalid parsing will raise an exception. If <code>coerce</code>, then invalid parsing will be set as <code>NaT</code>. If <code>ignore</code>, then invalid parsing will return the input.</p>  <code>'raise'</code>    <code>date_elements</code>  <code>[List[str]]</code>  <p>List of date elements to extract.</p>  <code>['year', 'month', 'day', 'day_of_week', 'day_of_year', 'week_of_year', 'quarter', 'is_leap_year', 'is_month_start', 'is_month_end', 'is_quarter_start', 'is_quarter_end', 'is_year_start', 'is_year_end', 'is_weekend']</code>      Source code in <code>src/sk_transformers/datetime_transformer.py</code> <pre><code>class DateColumnsTransformer(BaseTransformer):\n    \"\"\"Splits a date column into multiple columns.\n\n    Example:\n    ```python\n    import pandas as pd\n    from sk_transformers import DateColumnsTransformer\n\n    X = pd.DataFrame({\"foo\": [\"2021-01-01\", \"2022-02-02\", \"2023-03-03\"]})\n    transformer = DateColumnsTransformer([\"foo\"])\n    transformer.fit_transform(X)\n    ```\n    ```\n             foo  foo_year  ...  foo_is_year_end  foo_is_weekend\n    0 2021-01-01      2021  ...            False           False\n    1 2022-02-02      2022  ...            False           False\n    2 2023-03-03      2023  ...            False           False\n    ```\n\n    Args:\n        features (List[str]): List of columns to transform.\n        date_format (str): Date format. Defaults to `%Y-%m-%d`.\n        errors (str): How to handle errors in `pd.to_datetime`. Defaults to `raise`.\n            available values: `ignore`, `raise`, `coerce`.\n            If `raise`, then invalid parsing will raise an exception.\n            If `coerce`, then invalid parsing will be set as `NaT`.\n            If `ignore`, then invalid parsing will return the input.\n        date_elements ([List[str]]): List of date elements to extract.\n    \"\"\"\n\n    def __init__(  # pylint: disable=dangerous-default-value\n        self,\n        features: List[str],\n        date_format: str = \"%Y-%m-%d\",\n        errors: str = \"raise\",\n        date_elements: List[str] = [\n            \"year\",\n            \"month\",\n            \"day\",\n            \"day_of_week\",\n            \"day_of_year\",\n            \"week_of_year\",\n            \"quarter\",\n            \"is_leap_year\",\n            \"is_month_start\",\n            \"is_month_end\",\n            \"is_quarter_start\",\n            \"is_quarter_end\",\n            \"is_year_start\",\n            \"is_year_end\",\n            \"is_weekend\",\n        ],\n    ) -&gt; None:\n        super().__init__()\n        self.features = features\n        self.date_format = date_format\n        self.date_elements = date_elements\n        self.errors = errors\n\n    def transform(  # pylint: disable=too-many-branches\n        self, X: pd.DataFrame\n    ) -&gt; pd.DataFrame:\n        \"\"\"Transforms columns from the provided dataframe.\n\n        Args:\n            X (pandas.DataFrame): Dataframe with columns to transform.\n\n        Returns:\n            pandas.DataFrame: Dataframe with transformed columns.\n        \"\"\"\n\n        X = check_ready_to_transform(self, X, self.features, return_polars=True)\n\n        for column in self.features:  # pylint: disable=duplicate-code\n            X = X.with_columns(\n                pl.col(column)\n                .str.strptime(pl.Datetime, fmt=self.date_format)\n                .alias(column + \"_datetime\")\n            )\n\n            date_element_dict: Dict[str, pl.Expr] = {\n                \"year\": pl.col(f\"{column}_datetime\").dt.year(),\n                \"month\": pl.col(f\"{column}_datetime\").dt.month(),\n                \"day\": pl.col(f\"{column}_datetime\").dt.day(),\n                \"day_of_week\": pl.col(f\"{column}_datetime\").dt.weekday() - 1,\n                \"day_of_year\": pl.col(f\"{column}_datetime\").dt.ordinal_day(),\n                \"week_of_year\": pl.col(f\"{column}_datetime\").dt.week(),\n                \"quarter\": pl.col(f\"{column}_datetime\").dt.quarter(),\n                \"is_leap_year\": pl.col(f\"{column}_datetime\").dt.year() % 4 == 0,\n                \"is_month_start\": pl.col(f\"{column}_datetime\").dt.day() == 1,\n                \"is_month_end\": pl.col(f\"{column}_datetime\")\n                .dt.day()\n                .is_in([28, 29, 30, 31]),\n                \"is_quarter_start\": pl.col(f\"{column}_datetime\")\n                .dt.ordinal_day()\n                .is_in([1, 91, 183, 275]),\n                \"is_quarter_end\": pl.col(f\"{column}_datetime\")\n                .dt.ordinal_day()\n                .is_in([90, 182, 274, 365]),\n                \"is_year_start\": pl.col(f\"{column}_datetime\").dt.ordinal_day() == 1,\n                \"is_year_end\": pl.col(f\"{column}_datetime\")\n                .dt.ordinal_day()\n                .is_in([365, 366]),\n                \"is_weekend\": pl.col(f\"{column}_datetime\").dt.weekday().is_in([6, 7]),\n            }\n\n            X = X.with_columns(\n                [\n                    date_element_dict[element].alias(f\"{column}_{element}\")\n                    for element in self.date_elements\n                ]\n            ).drop(f\"{column}_datetime\")\n\n        return X.to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/datetime_transformer/#sk_transformers.datetime_transformer.DateColumnsTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Transforms columns from the provided dataframe.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pandas.DataFrame</code>  <p>Dataframe with columns to transform.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pandas.DataFrame: Dataframe with transformed columns.</p>     Source code in <code>src/sk_transformers/datetime_transformer.py</code> <pre><code>def transform(  # pylint: disable=too-many-branches\n    self, X: pd.DataFrame\n) -&gt; pd.DataFrame:\n    \"\"\"Transforms columns from the provided dataframe.\n\n    Args:\n        X (pandas.DataFrame): Dataframe with columns to transform.\n\n    Returns:\n        pandas.DataFrame: Dataframe with transformed columns.\n    \"\"\"\n\n    X = check_ready_to_transform(self, X, self.features, return_polars=True)\n\n    for column in self.features:  # pylint: disable=duplicate-code\n        X = X.with_columns(\n            pl.col(column)\n            .str.strptime(pl.Datetime, fmt=self.date_format)\n            .alias(column + \"_datetime\")\n        )\n\n        date_element_dict: Dict[str, pl.Expr] = {\n            \"year\": pl.col(f\"{column}_datetime\").dt.year(),\n            \"month\": pl.col(f\"{column}_datetime\").dt.month(),\n            \"day\": pl.col(f\"{column}_datetime\").dt.day(),\n            \"day_of_week\": pl.col(f\"{column}_datetime\").dt.weekday() - 1,\n            \"day_of_year\": pl.col(f\"{column}_datetime\").dt.ordinal_day(),\n            \"week_of_year\": pl.col(f\"{column}_datetime\").dt.week(),\n            \"quarter\": pl.col(f\"{column}_datetime\").dt.quarter(),\n            \"is_leap_year\": pl.col(f\"{column}_datetime\").dt.year() % 4 == 0,\n            \"is_month_start\": pl.col(f\"{column}_datetime\").dt.day() == 1,\n            \"is_month_end\": pl.col(f\"{column}_datetime\")\n            .dt.day()\n            .is_in([28, 29, 30, 31]),\n            \"is_quarter_start\": pl.col(f\"{column}_datetime\")\n            .dt.ordinal_day()\n            .is_in([1, 91, 183, 275]),\n            \"is_quarter_end\": pl.col(f\"{column}_datetime\")\n            .dt.ordinal_day()\n            .is_in([90, 182, 274, 365]),\n            \"is_year_start\": pl.col(f\"{column}_datetime\").dt.ordinal_day() == 1,\n            \"is_year_end\": pl.col(f\"{column}_datetime\")\n            .dt.ordinal_day()\n            .is_in([365, 366]),\n            \"is_weekend\": pl.col(f\"{column}_datetime\").dt.weekday().is_in([6, 7]),\n        }\n\n        X = X.with_columns(\n            [\n                date_element_dict[element].alias(f\"{column}_{element}\")\n                for element in self.date_elements\n            ]\n        ).drop(f\"{column}_datetime\")\n\n    return X.to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/datetime_transformer/#sk_transformers.datetime_transformer.DurationCalculatorTransformer","title":"<code>DurationCalculatorTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>Calculates the duration between to given dates.</p> <p>Example: <pre><code>import pandas as pd\nfrom sk_transformers import DurationCalculatorTransformer\n\nX = pd.DataFrame(\n    {\n        \"foo\": [\"1960-01-01\", \"1970-01-01\", \"1990-01-01\"],\n        \"bar\": [\"1960-01-01\", \"1971-01-01\", \"1988-01-01\"],\n    }\n)\ntransformer = DurationCalculatorTransformer((\"foo\", \"bar\"), \"days\", \"foo_bar_duration\")\ntransformer.fit_transform(X)\n</code></pre> <pre><code>          foo         bar  foo_bar_duration\n0  1960-01-01  1960-01-01                 0\n1  1970-01-01  1971-01-01               365\n2  1990-01-01  1988-01-01              -731\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>features</code>  <code>Tuple[str, str]</code>  <p>The two columns that contain the dates which should be used to calculate the duration.</p>  required    <code>unit</code>  <code>str</code>  <p>The unit in which the duration should be returned. Should be either <code>days</code> or <code>seconds</code>.</p>  required    <code>new_column_name</code>  <code>str</code>  <p>The name of the output column.</p>  required      Source code in <code>src/sk_transformers/datetime_transformer.py</code> <pre><code>class DurationCalculatorTransformer(BaseTransformer):\n    \"\"\"Calculates the duration between to given dates.\n\n    Example:\n    ```python\n    import pandas as pd\n    from sk_transformers import DurationCalculatorTransformer\n\n    X = pd.DataFrame(\n        {\n            \"foo\": [\"1960-01-01\", \"1970-01-01\", \"1990-01-01\"],\n            \"bar\": [\"1960-01-01\", \"1971-01-01\", \"1988-01-01\"],\n        }\n    )\n    transformer = DurationCalculatorTransformer((\"foo\", \"bar\"), \"days\", \"foo_bar_duration\")\n    transformer.fit_transform(X)\n    ```\n    ```\n              foo         bar  foo_bar_duration\n    0  1960-01-01  1960-01-01                 0\n    1  1970-01-01  1971-01-01               365\n    2  1990-01-01  1988-01-01              -731\n    ```\n\n    Args:\n        features (Tuple[str, str]): The two columns that contain the dates which should be used to calculate the duration.\n        unit (str): The unit in which the duration should be returned. Should be either `days` or `seconds`.\n        new_column_name (str): The name of the output column.\n    \"\"\"\n\n    def __init__(\n        self, features: Tuple[str, str], unit: str, new_column_name: str\n    ) -&gt; None:\n        super().__init__()\n        if unit not in [\"days\", \"seconds\"]:\n            raise ValueError(\"Unsupported unit. Should be either `days` or `seconds`!\")\n\n        self.features = features\n        self.unit = unit\n        self.new_column_name = new_column_name\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Transform method that calculates the duration between two dates.\n\n        Args:\n            X (pandas.DataFrame): The input DataFrame.\n\n        Returns:\n            pandas.DataFrame: The transformed DataFrame.\n        \"\"\"\n        X = check_ready_to_transform(self, X, list(self.features), return_polars=True)\n\n        if self.unit == \"seconds\":\n            return X.with_columns(\n                (\n                    pl.col(self.features[1]).str.strptime(pl.Datetime, fmt=\"%Y-%m-%d\")\n                    - pl.col(self.features[0]).str.strptime(pl.Datetime, fmt=\"%Y-%m-%d\")\n                )\n                .dt.seconds()\n                .alias(self.new_column_name)\n            ).to_pandas()\n        return X.with_columns(\n            (\n                pl.col(self.features[1]).str.strptime(pl.Datetime, fmt=\"%Y-%m-%d\")\n                - pl.col(self.features[0]).str.strptime(pl.Datetime, fmt=\"%Y-%m-%d\")\n            )\n            .dt.days()\n            .alias(self.new_column_name)\n        ).to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/datetime_transformer/#sk_transformers.datetime_transformer.DurationCalculatorTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Transform method that calculates the duration between two dates.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pandas.DataFrame</code>  <p>The input DataFrame.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pandas.DataFrame: The transformed DataFrame.</p>     Source code in <code>src/sk_transformers/datetime_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Transform method that calculates the duration between two dates.\n\n    Args:\n        X (pandas.DataFrame): The input DataFrame.\n\n    Returns:\n        pandas.DataFrame: The transformed DataFrame.\n    \"\"\"\n    X = check_ready_to_transform(self, X, list(self.features), return_polars=True)\n\n    if self.unit == \"seconds\":\n        return X.with_columns(\n            (\n                pl.col(self.features[1]).str.strptime(pl.Datetime, fmt=\"%Y-%m-%d\")\n                - pl.col(self.features[0]).str.strptime(pl.Datetime, fmt=\"%Y-%m-%d\")\n            )\n            .dt.seconds()\n            .alias(self.new_column_name)\n        ).to_pandas()\n    return X.with_columns(\n        (\n            pl.col(self.features[1]).str.strptime(pl.Datetime, fmt=\"%Y-%m-%d\")\n            - pl.col(self.features[0]).str.strptime(pl.Datetime, fmt=\"%Y-%m-%d\")\n        )\n        .dt.days()\n        .alias(self.new_column_name)\n    ).to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/datetime_transformer/#sk_transformers.datetime_transformer.TimestampTransformer","title":"<code>TimestampTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>Transforms a date column with a specified format into a timestamp column.</p> <p>Example: <pre><code>import pandas as pd\nfrom sk_transformers import TimestampTransformer\n\nX = pd.DataFrame({\"foo\": [\"1960-01-01\", \"1970-01-01\", \"1990-01-01\"]})\ntransformer = TimestampTransformer([\"foo\"])\ntransformer.fit_transform(X)\n</code></pre> <pre><code>           foo\n0 -315619200.0\n1          0.0\n2  631152000.0\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>features</code>  <code>List[str]</code>  <p>List of features which should be transformed.</p>  required    <code>date_format</code>  <code>str</code>  <p>Format of the date column. Defaults to \"%Y-%m-%d\".</p>  <code>'%Y-%m-%d'</code>      Source code in <code>src/sk_transformers/datetime_transformer.py</code> <pre><code>class TimestampTransformer(BaseTransformer):\n    \"\"\"Transforms a date column with a specified format into a timestamp\n    column.\n\n    Example:\n    ```python\n    import pandas as pd\n    from sk_transformers import TimestampTransformer\n\n    X = pd.DataFrame({\"foo\": [\"1960-01-01\", \"1970-01-01\", \"1990-01-01\"]})\n    transformer = TimestampTransformer([\"foo\"])\n    transformer.fit_transform(X)\n    ```\n    ```\n               foo\n    0 -315619200.0\n    1          0.0\n    2  631152000.0\n    ```\n\n    Args:\n        features (List[str]): List of features which should be transformed.\n        date_format (str): Format of the date column. Defaults to \"%Y-%m-%d\".\n    \"\"\"\n\n    def __init__(\n        self,\n        features: List[str],\n        date_format: str = \"%Y-%m-%d\",\n    ) -&gt; None:\n        super().__init__()\n        self.features = features\n        self.date_format = date_format\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Transforms columns from the provided dataframe.\n\n        Args:\n            X (pandas.DataFrame): Dataframe with columns to transform.\n\n        Returns:\n            pandas.DataFrame: Dataframe with transformed columns.\n        \"\"\"\n        X = check_ready_to_transform(self, X, self.features, return_polars=True)\n\n        return X.with_columns(\n            [\n                pl.col(column)\n                .str.strptime(pl.Datetime, self.date_format)\n                .dt.timestamp(\"ms\")\n                / 1000\n                for column in self.features\n            ]\n        ).to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/datetime_transformer/#sk_transformers.datetime_transformer.TimestampTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Transforms columns from the provided dataframe.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pandas.DataFrame</code>  <p>Dataframe with columns to transform.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pandas.DataFrame: Dataframe with transformed columns.</p>     Source code in <code>src/sk_transformers/datetime_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Transforms columns from the provided dataframe.\n\n    Args:\n        X (pandas.DataFrame): Dataframe with columns to transform.\n\n    Returns:\n        pandas.DataFrame: Dataframe with transformed columns.\n    \"\"\"\n    X = check_ready_to_transform(self, X, self.features, return_polars=True)\n\n    return X.with_columns(\n        [\n            pl.col(column)\n            .str.strptime(pl.Datetime, self.date_format)\n            .dt.timestamp(\"ms\")\n            / 1000\n            for column in self.features\n        ]\n    ).to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/encoder_transformer/","title":"Encoder transformer","text":""},{"location":"API-reference/transformer/encoder_transformer/#sk_transformers.encoder_transformer.MeanEncoderTransformer","title":"<code>MeanEncoderTransformer</code>","text":"<p>         Bases: <code>BaseEstimator</code>, <code>TransformerMixin</code></p> <p>Scikit-learn API for the feature-engine MeanEncoder.</p> <p>Example: <pre><code>import pandas as pd\nfrom sk_transformers import MeanEncoderTransformer\n\nX = pd.DataFrame({\"foo\": [\"a\", \"b\", \"a\", \"c\", \"b\", \"a\", \"c\", \"a\", \"b\", \"c\"]})\ny = pd.Series([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n\nencoder = MeanEncoderTransformer()\nencoder.fit_transform(X, y)\n</code></pre> <pre><code>        foo\n0  0.500000\n1  0.666667\n2  0.500000\n3  0.333333\n4  0.666667\n5  0.500000\n6  0.333333\n7  0.500000\n8  0.666667\n9  0.333333\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>fill_na_value</code>  <code>Union[int, float]</code>  <p>Value to fill NaN values with. Those may appear if a category is not present in the set the encoder was not fitted on.</p>  <code>-999</code>      Source code in <code>src/sk_transformers/encoder_transformer.py</code> <pre><code>class MeanEncoderTransformer(BaseEstimator, TransformerMixin):\n    \"\"\"Scikit-learn API for the [feature-engine MeanEncoder](https://feature-\n    engine.readthedocs.io/en/latest/api_doc/encoding/MeanEncoder.html).\n\n    Example:\n    ```python\n    import pandas as pd\n    from sk_transformers import MeanEncoderTransformer\n\n    X = pd.DataFrame({\"foo\": [\"a\", \"b\", \"a\", \"c\", \"b\", \"a\", \"c\", \"a\", \"b\", \"c\"]})\n    y = pd.Series([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n\n    encoder = MeanEncoderTransformer()\n    encoder.fit_transform(X, y)\n    ```\n    ```\n            foo\n    0  0.500000\n    1  0.666667\n    2  0.500000\n    3  0.333333\n    4  0.666667\n    5  0.500000\n    6  0.333333\n    7  0.500000\n    8  0.666667\n    9  0.333333\n    ```\n\n    Args:\n        fill_na_value (Union[int, float]): Value to fill NaN values with.\n            Those may appear if a category is not present in the set the encoder was not fitted on.\n    \"\"\"\n\n    def __init__(self, fill_na_value: Union[int, float] = -999) -&gt; None:\n        self.encoder = MeanEncoder(ignore_format=False)\n        self.fill_na_value = fill_na_value\n\n    def fit(self, X: pd.DataFrame, y: pd.Series) -&gt; \"MeanEncoderTransformer\":\n        \"\"\"Fit the MeanEncoder to the data.\n\n        Args:\n            X (pandas.DataFrame): DataFrame to fit the MeanEncoder to.\n            y (pandas.Series): Target variable.\n\n        Returns:\n            MeanEncoder: Fitted MeanEncoder.\n        \"\"\"\n        self.encoder.fit(X, y)\n        return self\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Transform the data using the fitted MeanEncoder.\n\n        Args:\n            X (pandas.DataFrame): DataFrame to transform.\n\n        Returns:\n            pandas.DataFrame: Transformed DataFrame.\n        \"\"\"\n        return self.encoder.transform(X).fillna(self.fill_na_value)\n</code></pre>"},{"location":"API-reference/transformer/encoder_transformer/#sk_transformers.encoder_transformer.MeanEncoderTransformer.fit","title":"<code>fit(X, y)</code>","text":"<p>Fit the MeanEncoder to the data.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pandas.DataFrame</code>  <p>DataFrame to fit the MeanEncoder to.</p>  required    <code>y</code>  <code>pandas.Series</code>  <p>Target variable.</p>  required     <p>Returns:</p>    Name Type Description     <code>MeanEncoder</code>  <code>MeanEncoderTransformer</code>  <p>Fitted MeanEncoder.</p>     Source code in <code>src/sk_transformers/encoder_transformer.py</code> <pre><code>def fit(self, X: pd.DataFrame, y: pd.Series) -&gt; \"MeanEncoderTransformer\":\n    \"\"\"Fit the MeanEncoder to the data.\n\n    Args:\n        X (pandas.DataFrame): DataFrame to fit the MeanEncoder to.\n        y (pandas.Series): Target variable.\n\n    Returns:\n        MeanEncoder: Fitted MeanEncoder.\n    \"\"\"\n    self.encoder.fit(X, y)\n    return self\n</code></pre>"},{"location":"API-reference/transformer/encoder_transformer/#sk_transformers.encoder_transformer.MeanEncoderTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Transform the data using the fitted MeanEncoder.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pandas.DataFrame</code>  <p>DataFrame to transform.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pandas.DataFrame: Transformed DataFrame.</p>     Source code in <code>src/sk_transformers/encoder_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Transform the data using the fitted MeanEncoder.\n\n    Args:\n        X (pandas.DataFrame): DataFrame to transform.\n\n    Returns:\n        pandas.DataFrame: Transformed DataFrame.\n    \"\"\"\n    return self.encoder.transform(X).fillna(self.fill_na_value)\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/","title":"Generic transformer","text":""},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.AggregateTransformer","title":"<code>AggregateTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>This transformer uses Pandas <code>groupby</code> method and <code>aggregate</code> to apply function on a column grouped by another column. Read more about Pandas <code>aggregate</code> method to understand how to use function for aggregation. Other than Pandas function this transformer only support functions and string- names.</p> <p>Internally this transformer uses Polars. You may encounter issues with your implementation. Please check the Polars documentation for more information: https://pola-rs.github.io/polars/py-polars/html/reference/</p> <p>Example: <pre><code>import pandas as pd\nfrom sk_transformers import AggregateTransformer\n\nX = pd.DataFrame(\n    {\n        \"foo\": [\"mr\", \"mr\", \"ms\", \"ms\", \"ms\", \"mr\", \"mr\", \"mr\", \"mr\", \"ms\"],\n        \"bar\": [46, 32, 78, 48, 93, 68, 53, 38, 76, 56],\n    }\n)\n\ntransformer = AggregateTransformer([(\"foo\", (\"bar\", \"mean\", \"MEAN(foo_bar)\"))])\ntransformer.fit_transform(X)\n</code></pre> <pre><code>  foo  bar  MEAN(foo_bar)\n0  mr   46       52.166668\n1  mr   32       52.166668\n2  ms   78       68.750000\n3  ms   48       68.750000\n4  ms   93       68.750000\n5  mr   68       52.166668\n6  mr   53       52.166668\n7  mr   38       52.166668\n8  mr   76       52.166668\n9  ms   56       68.750000\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>features</code>  <code>List[Tuple[str, Tuple[str, Union[str, Callable], str]]]</code>  <p>List of tuples where the first element is the name or the list of names of columns to be grouped-by, and the second element is a tuple or list of tuples containing the aggregation information. In this tuple, the first element is the name of the column to be aggregated, the second element is the aggregation function as a string or function object, and the third element is the name of the new aggregated column.</p>  required      Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>class AggregateTransformer(BaseTransformer):\n    \"\"\"This transformer uses Pandas `groupby` method and `aggregate` to apply\n    function on a column grouped by another column. Read more about Pandas\n    `aggregate` method to understand how to use function for aggregation. Other\n    than Pandas function this transformer only support functions and string-\n    names.\n\n    Internally this transformer uses Polars. You may encounter issues with your implementation.\n    Please check the Polars documentation for more information:\n    https://pola-rs.github.io/polars/py-polars/html/reference/\n\n    Example:\n    ```python\n    import pandas as pd\n    from sk_transformers import AggregateTransformer\n\n    X = pd.DataFrame(\n        {\n            \"foo\": [\"mr\", \"mr\", \"ms\", \"ms\", \"ms\", \"mr\", \"mr\", \"mr\", \"mr\", \"ms\"],\n            \"bar\": [46, 32, 78, 48, 93, 68, 53, 38, 76, 56],\n        }\n    )\n\n    transformer = AggregateTransformer([(\"foo\", (\"bar\", \"mean\", \"MEAN(foo_bar)\"))])\n    transformer.fit_transform(X)\n    ```\n    ```\n      foo  bar  MEAN(foo_bar)\n    0  mr   46       52.166668\n    1  mr   32       52.166668\n    2  ms   78       68.750000\n    3  ms   48       68.750000\n    4  ms   93       68.750000\n    5  mr   68       52.166668\n    6  mr   53       52.166668\n    7  mr   38       52.166668\n    8  mr   76       52.166668\n    9  ms   56       68.750000\n    ```\n\n    Args:\n        features (List[Tuple[str, Tuple[str, Union[str, Callable], str]]]): List of tuples where\n            the first element is the name or the list of names of columns to be grouped-by,\n            and the second element is a tuple or list of tuples containing the aggregation information.\n            In this tuple, the first element is the name of the column to be aggregated,\n            the second element is the aggregation function as a string or function object,\n            and the third element is the name of the new aggregated column.\n    \"\"\"\n\n    def __init__(\n        self,\n        features: List[\n            Tuple[\n                Union[str, List[str]],\n                Union[\n                    Tuple[str, Union[str, Callable], str],\n                    List[Tuple[str, Union[str, Callable], str]],\n                ],\n            ]\n        ],\n    ) -&gt; None:\n        super().__init__()\n        self.features = features\n\n    def __get_list_of_features(self) -&gt; List[str]:\n        feature_list = []\n\n        for groupby_columns, agg_features in self.features:\n            if isinstance(groupby_columns, str):\n                groupby_columns = [groupby_columns]\n            for groupby_column in groupby_columns:\n                feature_list.append(groupby_column)\n\n            if isinstance(agg_features, tuple):\n                agg_features = [agg_features]\n            for agg_column, _, _ in agg_features:\n                feature_list.append(agg_column)\n\n        return list(set(feature_list))\n\n    def __check_input(self) -&gt; None:\n        for feature in self.features:\n            if len(feature) != 2:\n                raise IndexError(\n                    f\"Expected 2 elements in the feature tuple, got {len(feature)}.\"\n                )\n\n            agg_features = feature[1]\n\n            if isinstance(agg_features, tuple):\n                agg_features = [agg_features]\n            if isinstance(agg_features, list):\n                for agg_feature in agg_features:\n                    if isinstance(agg_feature, tuple):\n                        if len(agg_feature) != 3:\n                            raise IndexError(\n                                f\"Expected 3 elements in the aggregation tuple, got {len(agg_feature)}.\"\n                            )\n                    else:\n                        raise TypeError(\n                            f\"Expected a list of tuples, found {type(agg_feature).__name__} in list.\"\n                        )\n\n                    func = agg_feature[1]\n                    if isinstance(func, str) is False:\n                        func = func.__name__  # type: ignore\n                    if func == \"&lt;lambda&gt;\":\n                        warnings.warn(\n                            \"\"\"\n                        Internally this transformer uses Polars. You may encounter issues with your lambda implementation.\n                        Please check the documentation for correct syntax and functionality:\n                        https://pola-rs.github.io/polars-book/user-guide/dsl/custom_functions.html\n                        \"\"\",\n                            SyntaxWarning,\n                        )\n\n            else:\n                raise TypeError(\n                    f\"Expected a list or tuple of aggregations, got {type(agg_features).__name__}.\"\n                )\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Creates new columns by using Pandas `groupby` method and `aggregate`\n        to apply function on the column.\n\n        Args:\n            X (pd.DataFrame): Input dataframe.\n\n        Returns:\n            pd.DataFrame: Transformed dataframe. It contains the original columns and the new columns created by this transformer.\n        \"\"\"\n        self.__check_input()\n        X = check_ready_to_transform(\n            self,\n            X,\n            self.__get_list_of_features(),\n            return_polars=True,\n        )\n\n        for groupby_columns, agg_features in self.features:\n            if isinstance(agg_features, tuple):\n                agg_features = [agg_features]\n\n            agg_df = X.groupby(groupby_columns).agg(\n                [\n                    getattr(pl, agg_func)(agg_column).alias(agg_new_column)\n                    if isinstance(agg_func, str)\n                    else pl.col(agg_column).apply(agg_func).alias(agg_new_column)\n                    for (agg_column, agg_func, agg_new_column) in agg_features\n                ]\n            )\n            X = X.join(agg_df, on=groupby_columns)\n\n        return X.to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.AggregateTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Creates new columns by using Pandas <code>groupby</code> method and <code>aggregate</code> to apply function on the column.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pd.DataFrame</code>  <p>Input dataframe.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pd.DataFrame: Transformed dataframe. It contains the original columns and the new columns created by this transformer.</p>     Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Creates new columns by using Pandas `groupby` method and `aggregate`\n    to apply function on the column.\n\n    Args:\n        X (pd.DataFrame): Input dataframe.\n\n    Returns:\n        pd.DataFrame: Transformed dataframe. It contains the original columns and the new columns created by this transformer.\n    \"\"\"\n    self.__check_input()\n    X = check_ready_to_transform(\n        self,\n        X,\n        self.__get_list_of_features(),\n        return_polars=True,\n    )\n\n    for groupby_columns, agg_features in self.features:\n        if isinstance(agg_features, tuple):\n            agg_features = [agg_features]\n\n        agg_df = X.groupby(groupby_columns).agg(\n            [\n                getattr(pl, agg_func)(agg_column).alias(agg_new_column)\n                if isinstance(agg_func, str)\n                else pl.col(agg_column).apply(agg_func).alias(agg_new_column)\n                for (agg_column, agg_func, agg_new_column) in agg_features\n            ]\n        )\n        X = X.join(agg_df, on=groupby_columns)\n\n    return X.to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.AllowedValuesTransformer","title":"<code>AllowedValuesTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>Replaces all values that are not in a list of allowed values with a replacement value. This performs an complementary transformation to that of the ValueReplacerTransformer. This is useful while lumping several minor categories together by selecting them using a list of major categories.</p> <p>Example: <pre><code>import pandas as pd\nfrom sk_transformers.generic_transformer import AllowedValuesTransformer\n\nX = pd.DataFrame({\"foo\": [\"a\", \"b\", \"c\", \"d\", \"e\"]})\ntransformer = AllowedValuesTransformer([(\"foo\", [\"a\", \"b\"], \"other\")])\ntransformer.fit_transform(X)\n</code></pre> <pre><code>     foo\n0      a\n1      b\n2  other\n3  other\n4  other\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>features</code>  <code>List[Tuple[str, List[Any], Any]]</code>  <p>List of tuples where the first element is the column name, the second element is the list of allowed values in the column, and the third element is the value to replace disallowed values in the column.</p>  required      Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>class AllowedValuesTransformer(BaseTransformer):\n    \"\"\"Replaces all values that are not in a list of allowed values with a\n    replacement value. This performs an complementary transformation to that of\n    the ValueReplacerTransformer. This is useful while lumping several minor\n    categories together by selecting them using a list of major categories.\n\n    Example:\n    ```python\n    import pandas as pd\n    from sk_transformers.generic_transformer import AllowedValuesTransformer\n\n    X = pd.DataFrame({\"foo\": [\"a\", \"b\", \"c\", \"d\", \"e\"]})\n    transformer = AllowedValuesTransformer([(\"foo\", [\"a\", \"b\"], \"other\")])\n    transformer.fit_transform(X)\n    ```\n    ```\n         foo\n    0      a\n    1      b\n    2  other\n    3  other\n    4  other\n    ```\n\n    Args:\n        features (List[Tuple[str, List[Any], Any]]): List of tuples where\n            the first element is the column name,\n            the second element is the list of allowed values in the column, and\n            the third element is the value to replace disallowed values in the column.\n    \"\"\"\n\n    def __init__(self, features: List[Tuple[str, List[Any], Any]]) -&gt; None:\n        super().__init__()\n        self.features = features\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Replaces values not in a list with another value.\n\n        Args:\n            X (pd.DataFrame): Dataframe containing the columns with values to be replaced.\n\n        Returns:\n            pd.DataFrame: Dataframe with replaced values.\n        \"\"\"\n        X = check_ready_to_transform(\n            self, X, [feature[0] for feature in self.features], return_polars=True\n        )\n\n        return X.with_columns(\n            [\n                pl.col(column)\n                .map_dict(\n                    {allowed_value: allowed_value for allowed_value in allowed_values}\n                )\n                .cast(type(replacement))\n                .fill_null(replacement)\n                for column, allowed_values, replacement in self.features\n            ]\n        ).to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.AllowedValuesTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Replaces values not in a list with another value.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pd.DataFrame</code>  <p>Dataframe containing the columns with values to be replaced.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pd.DataFrame: Dataframe with replaced values.</p>     Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Replaces values not in a list with another value.\n\n    Args:\n        X (pd.DataFrame): Dataframe containing the columns with values to be replaced.\n\n    Returns:\n        pd.DataFrame: Dataframe with replaced values.\n    \"\"\"\n    X = check_ready_to_transform(\n        self, X, [feature[0] for feature in self.features], return_polars=True\n    )\n\n    return X.with_columns(\n        [\n            pl.col(column)\n            .map_dict(\n                {allowed_value: allowed_value for allowed_value in allowed_values}\n            )\n            .cast(type(replacement))\n            .fill_null(replacement)\n            for column, allowed_values, replacement in self.features\n        ]\n    ).to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.ColumnDropperTransformer","title":"<code>ColumnDropperTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>Drops columns from a dataframe using Pandas <code>drop</code> method.</p> <p>Example: <pre><code>import pandas as pd\nfrom sk_transformers import ColumnDropperTransformer\n\nX = pd.DataFrame({\"foo\": [1, 2, 3], \"bar\": [4, 5, 6]})\ntransformer = ColumnDropperTransformer([\"foo\"])\ntransformer.fit_transform(X)\n</code></pre> <pre><code>   bar\n0    4\n1    5\n2    6\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>columns</code>  <code>Union[str, List[str]]</code>  <p>Columns to drop. Either a single column name or a list of column names.</p>  required      Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>class ColumnDropperTransformer(BaseTransformer):\n    \"\"\"Drops columns from a dataframe using Pandas `drop` method.\n\n    Example:\n    ```python\n    import pandas as pd\n    from sk_transformers import ColumnDropperTransformer\n\n    X = pd.DataFrame({\"foo\": [1, 2, 3], \"bar\": [4, 5, 6]})\n    transformer = ColumnDropperTransformer([\"foo\"])\n    transformer.fit_transform(X)\n    ```\n    ```\n       bar\n    0    4\n    1    5\n    2    6\n    ```\n\n    Args:\n        columns (Union[str, List[str]]): Columns to drop. Either a single column name or a list of column names.\n    \"\"\"\n\n    def __init__(self, columns: Union[str, List[str]]) -&gt; None:\n        super().__init__()\n        self.columns = columns\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Returns the dataframe with the `columns` dropped.\n\n        Args:\n            X (pd.DataFrame): Dataframe to drop columns from.\n\n        Returns:\n            pd.DataFrame: Dataframe with columns dropped.\n        \"\"\"\n        X = check_ready_to_transform(self, X, self.columns, force_all_finite=False)\n        return X.drop(columns=self.columns)\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.ColumnDropperTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Returns the dataframe with the <code>columns</code> dropped.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pd.DataFrame</code>  <p>Dataframe to drop columns from.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pd.DataFrame: Dataframe with columns dropped.</p>     Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Returns the dataframe with the `columns` dropped.\n\n    Args:\n        X (pd.DataFrame): Dataframe to drop columns from.\n\n    Returns:\n        pd.DataFrame: Dataframe with columns dropped.\n    \"\"\"\n    X = check_ready_to_transform(self, X, self.columns, force_all_finite=False)\n    return X.drop(columns=self.columns)\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.ColumnEvalTransformer","title":"<code>ColumnEvalTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>Provides the possibility to use Pandas methods on columns. Internally this transformer uses Polars. You may encounter issues with your implementation. Please check the Polars documentation for more information: https://pola-rs.github.io/polars/py-polars/html/reference/</p> <p>Example: <pre><code>import pandas as pd\nfrom sk_transformers import ColumnEvalTransformer\n\n# In this example we use Polars implementation of Pandas `str.upper()`: `str.to_uppercase()`.\n\nX = pd.DataFrame({\"foo\": [\"a\", \"b\", \"c\"], \"bar\": [1, 2, 3]})\ntransformer = ColumnEvalTransformer(\n    [(\"foo\", \"str.to_uppercase()\"), (\"bar\", \"apply(lambda x: x + 1)\")]\n)\ntransformer.fit_transform(X)\n</code></pre> <pre><code>   foo  bar\n0    A    2\n1    B    3\n2    C    4\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>features</code>  <code>List[Union[Tuple[str, str], Tuple[str, str, str]]]</code>  <p>List of tuples containing the column name and the method (<code>eval_func</code>) to apply. As a third entry in the tuple an alternative name for the column can be provided. If not provided the column name will be used. This can be useful if the the original column should not be replaced but another column should be created.</p>  required     <p>Raises:</p>    Type Description      <code>ValueError</code>  <p>If the <code>eval_func</code> starts with a dot (<code>.</code>).</p>    <code>ValueError</code>  <p>If the <code>eval_func</code> tries to assign multiple columns to one target column.</p>     Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>class ColumnEvalTransformer(BaseTransformer):\n    \"\"\"Provides the possibility to use Pandas methods on columns. Internally\n    this transformer uses Polars. You may encounter issues with your\n    implementation. Please check the Polars documentation for more information:\n    https://pola-rs.github.io/polars/py-polars/html/reference/\n\n    Example:\n    ```python\n    import pandas as pd\n    from sk_transformers import ColumnEvalTransformer\n\n    # In this example we use Polars implementation of Pandas `str.upper()`: `str.to_uppercase()`.\n\n    X = pd.DataFrame({\"foo\": [\"a\", \"b\", \"c\"], \"bar\": [1, 2, 3]})\n    transformer = ColumnEvalTransformer(\n        [(\"foo\", \"str.to_uppercase()\"), (\"bar\", \"apply(lambda x: x + 1)\")]\n    )\n    transformer.fit_transform(X)\n    ```\n    ```\n       foo  bar\n    0    A    2\n    1    B    3\n    2    C    4\n    ```\n\n    Args:\n        features (List[Union[Tuple[str, str], Tuple[str, str, str]]]): List of tuples containing the column name and the method (`eval_func`) to apply.\n            As a third entry in the tuple an alternative name for the column can be provided. If not provided the column name will be used.\n            This can be useful if the the original column should not be replaced but another column should be created.\n\n    Raises:\n        ValueError: If the `eval_func` starts with a dot (`.`).\n        ValueError: If the `eval_func` tries to assign multiple columns to one target column.\n    \"\"\"\n\n    __slots__ = (\"features\",)\n\n    def __init__(\n        self, features: List[Union[Tuple[str, str], Tuple[str, str, str]]]\n    ) -&gt; None:\n        super().__init__()  # pylint: disable=duplicate-code\n        self.features = features\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Transform the dataframe by using the `eval` function provided.\n\n        Args:\n            X (pandas.DataFrame): dataframe to transform.\n        Returns:\n            pandas.DataFrame: Transformed dataframe.\n        \"\"\"\n        X = check_ready_to_transform(\n            self,\n            X,\n            [feature[0] for feature in self.features],\n            force_all_finite=\"allow-nan\",\n            return_polars=True,\n        )\n\n        for eval_tuple in self.features:\n            column = eval_tuple[0]\n            eval_func = eval_tuple[1]\n            new_column = eval_tuple[2] if len(eval_tuple) == 3 else column  # type: ignore # pylint: disable=unused-variable\n\n            if eval_func[0] == \".\":\n                raise ValueError(\n                    \"The provided `eval_func` must not start with a dot! Just write e.g. `str.len()` instead of `.str.len()`.\"\n                )\n\n            try:\n                X = X.with_columns(\n                    eval(  # pylint: disable=eval-used # nosec\n                        f\"pl.col({'column'}).{eval_func}.alias({'new_column'})\"\n                    )\n                )\n            except AttributeError as error:\n                raise AttributeError(\n                    f\"\"\"Internally this transformer uses Polars. You may encounter issues with your implementation.\n                    Please check the Polars documentation for more information:\n                    https://pola-rs.github.io/polars/py-polars/html/reference/\n                    Original error: {error}\"\"\"\n                ) from error\n\n        return X.to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.ColumnEvalTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Transform the dataframe by using the <code>eval</code> function provided.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pandas.DataFrame</code>  <p>dataframe to transform.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pandas.DataFrame: Transformed dataframe.</p>     Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Transform the dataframe by using the `eval` function provided.\n\n    Args:\n        X (pandas.DataFrame): dataframe to transform.\n    Returns:\n        pandas.DataFrame: Transformed dataframe.\n    \"\"\"\n    X = check_ready_to_transform(\n        self,\n        X,\n        [feature[0] for feature in self.features],\n        force_all_finite=\"allow-nan\",\n        return_polars=True,\n    )\n\n    for eval_tuple in self.features:\n        column = eval_tuple[0]\n        eval_func = eval_tuple[1]\n        new_column = eval_tuple[2] if len(eval_tuple) == 3 else column  # type: ignore # pylint: disable=unused-variable\n\n        if eval_func[0] == \".\":\n            raise ValueError(\n                \"The provided `eval_func` must not start with a dot! Just write e.g. `str.len()` instead of `.str.len()`.\"\n            )\n\n        try:\n            X = X.with_columns(\n                eval(  # pylint: disable=eval-used # nosec\n                    f\"pl.col({'column'}).{eval_func}.alias({'new_column'})\"\n                )\n            )\n        except AttributeError as error:\n            raise AttributeError(\n                f\"\"\"Internally this transformer uses Polars. You may encounter issues with your implementation.\n                Please check the Polars documentation for more information:\n                https://pola-rs.github.io/polars/py-polars/html/reference/\n                Original error: {error}\"\"\"\n            ) from error\n\n    return X.to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.DtypeTransformer","title":"<code>DtypeTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>Transformer that converts a column to a different dtype.</p> <p>Example: <pre><code>import numpy as np\nimport pandas as pd\nfrom sk_transformers import DtypeTransformer\n\nX = pd.DataFrame({\"foo\": [1, 2, 3], \"bar\": [\"a\", \"a\", \"b\"]})\ntransformer = DtypeTransformer([(\"foo\", np.float32), (\"bar\", \"category\")])\ntransformer.fit_transform(X).dtypes\n</code></pre> <pre><code>foo     float32\nbar    category\ndtype: object\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>features</code>  <code>List[Tuple[str, Union[str, type]]]</code>  <p>List of tuples containing the column name and the dtype (<code>str</code> or <code>type</code>).</p>  required      Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>class DtypeTransformer(BaseTransformer):\n    \"\"\"Transformer that converts a column to a different dtype.\n\n    Example:\n    ```python\n    import numpy as np\n    import pandas as pd\n    from sk_transformers import DtypeTransformer\n\n    X = pd.DataFrame({\"foo\": [1, 2, 3], \"bar\": [\"a\", \"a\", \"b\"]})\n    transformer = DtypeTransformer([(\"foo\", np.float32), (\"bar\", \"category\")])\n    transformer.fit_transform(X).dtypes\n    ```\n    ```\n    foo     float32\n    bar    category\n    dtype: object\n    ```\n\n    Args:\n        features (List[Tuple[str, Union[str, type]]]): List of tuples containing the column name and the dtype (`str` or `type`).\n    \"\"\"\n\n    def __init__(self, features: List[Tuple[str, Union[str, type]]]) -&gt; None:\n        super().__init__()\n        self.features = features\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Transform the dataframe by converting the columns to the specified\n        dtypes.\n\n        Args:\n            X (pandas.DataFrame): dataframe to transform.\n\n        Returns:\n            pandas.DataFrame: Transformed dataframe.\n        \"\"\"\n        X = check_ready_to_transform(\n            self,\n            X,\n            [feature[0] for feature in self.features],\n            force_all_finite=\"allow-nan\",\n        )\n\n        for column, dtype in self.features:\n            X[column] = X[column].astype(dtype)\n        return X\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.DtypeTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Transform the dataframe by converting the columns to the specified dtypes.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pandas.DataFrame</code>  <p>dataframe to transform.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pandas.DataFrame: Transformed dataframe.</p>     Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Transform the dataframe by converting the columns to the specified\n    dtypes.\n\n    Args:\n        X (pandas.DataFrame): dataframe to transform.\n\n    Returns:\n        pandas.DataFrame: Transformed dataframe.\n    \"\"\"\n    X = check_ready_to_transform(\n        self,\n        X,\n        [feature[0] for feature in self.features],\n        force_all_finite=\"allow-nan\",\n    )\n\n    for column, dtype in self.features:\n        X[column] = X[column].astype(dtype)\n    return X\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.FunctionsTransformer","title":"<code>FunctionsTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>This transformer is a plain wrapper around the.</p> <p><code>sklearn.preprocessing.FunctionTransformer</code>. Its main function is to apply multiple functions to different columns. Other than the scikit-learn transformer, this transformer does not support the <code>inverse_func</code>, <code>accept_sparse</code>, <code>feature_names_out</code> and, <code>inv_kw_args</code> parameters.</p> <p>Example: <pre><code>import numpy as np\nimport pandas as pd\nfrom sk_transformers import FunctionsTransformer\n\nX = pd.DataFrame({\"foo\": [1, 2, 3], \"bar\": [4, 5, 6]})\ntransformer = FunctionsTransformer([(\"foo\", np.log1p, None), (\"bar\", np.sqrt, None)])\ntransformer.fit_transform(X)\n</code></pre> <pre><code>        foo       bar\n0  0.693147  2.000000\n1  1.098612  2.236068\n2  1.386294  2.449490\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>features</code>  <code>List[str, Callable, Optional[Dict[str, Any]]]</code>  <p>List of tuples containing the name of the column to apply the function on and the function itself. As well as a dictionary passed to the function as <code>kwargs</code>.</p>  required      Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>class FunctionsTransformer(BaseTransformer):\n    \"\"\"This transformer is a plain wrapper around the.\n\n    [`sklearn.preprocessing.FunctionTransformer`](https://scikit-learn.org/stab\n    le/modules/generated/sklearn.preprocessing.FunctionTransformer.html). Its\n    main function is to apply multiple functions to different columns. Other\n    than the scikit-learn transformer, this transformer *does not* support the\n    `inverse_func`, `accept_sparse`, `feature_names_out` and, `inv_kw_args`\n    parameters.\n\n    Example:\n    ```python\n    import numpy as np\n    import pandas as pd\n    from sk_transformers import FunctionsTransformer\n\n    X = pd.DataFrame({\"foo\": [1, 2, 3], \"bar\": [4, 5, 6]})\n    transformer = FunctionsTransformer([(\"foo\", np.log1p, None), (\"bar\", np.sqrt, None)])\n    transformer.fit_transform(X)\n    ```\n    ```\n            foo       bar\n    0  0.693147  2.000000\n    1  1.098612  2.236068\n    2  1.386294  2.449490\n    ```\n\n    Args:\n        features (List[str, Callable, Optional[Dict[str, Any]]]): List of tuples containing the name of the\n            column to apply the function on and the function itself.\n            As well as a dictionary passed to the function as `kwargs`.\n    \"\"\"\n\n    def __init__(\n        self, features: List[Tuple[str, Callable, Optional[Dict[str, Any]]]]\n    ) -&gt; None:\n        super().__init__()\n        self.features = features\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Applies the functions to the columns, and returns the dataframe with\n        the modified columns.\n\n        Args:\n            X (pandas.DataFrame): DataFrame containing the columns to apply the functions on.\n\n        Returns:\n            pandas.DataFrame: The original dataframe with the modified columns.\n        \"\"\"\n        X = check_ready_to_transform(self, X, [feature[0] for feature in self.features])\n\n        for column, func, kwargs in self.features:\n            X[column] = FunctionTransformer(\n                func, validate=True, kw_args=kwargs\n            ).transform(X[[column]].to_numpy())\n\n        return X\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.FunctionsTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Applies the functions to the columns, and returns the dataframe with the modified columns.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pandas.DataFrame</code>  <p>DataFrame containing the columns to apply the functions on.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pandas.DataFrame: The original dataframe with the modified columns.</p>     Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Applies the functions to the columns, and returns the dataframe with\n    the modified columns.\n\n    Args:\n        X (pandas.DataFrame): DataFrame containing the columns to apply the functions on.\n\n    Returns:\n        pandas.DataFrame: The original dataframe with the modified columns.\n    \"\"\"\n    X = check_ready_to_transform(self, X, [feature[0] for feature in self.features])\n\n    for column, func, kwargs in self.features:\n        X[column] = FunctionTransformer(\n            func, validate=True, kw_args=kwargs\n        ).transform(X[[column]].to_numpy())\n\n    return X\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.LeftJoinTransformer","title":"<code>LeftJoinTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>Performs a database-style left-join using <code>pd.merge</code>. This transformer is suitable for replacing values in a column of a dataframe by looking-up another <code>pd.DataFrame</code> or <code>pd.Series</code>. Note that, the join is based on the index of the right dataframe.</p> <p>Example: <pre><code>import pandas as pd\nfrom sk_transformers import LeftJoinTransformer\n\nX = pd.DataFrame({\"foo\": [\"A\", \"B\", \"C\", \"A\", \"C\"]})\nlookup_df = pd.Series([1, 2, 3], index=[\"A\", \"B\", \"C\"], name=\"values\")\ntransformer = LeftJoinTransformer([(\"foo\", lookup_df)])\ntransformer.fit_transform(X)\n</code></pre> <pre><code>  foo  foo_values\n0   A           1\n1   B           2\n2   C           3\n3   A           1\n4   C           3\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>features</code>  <code>List[Tuple[str, Union[pd.Series, pd.DataFrame]]]</code>  <p>A list of tuples where the first element is the name of the column and the second element is the look-up dataframe or series.</p>  required      Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>class LeftJoinTransformer(BaseTransformer):\n    \"\"\"Performs a database-style left-join using `pd.merge`. This transformer\n    is suitable for replacing values in a column of a dataframe by looking-up\n    another `pd.DataFrame` or `pd.Series`. Note that, the join is based on the\n    index of the right dataframe.\n\n    Example:\n    ```python\n    import pandas as pd\n    from sk_transformers import LeftJoinTransformer\n\n    X = pd.DataFrame({\"foo\": [\"A\", \"B\", \"C\", \"A\", \"C\"]})\n    lookup_df = pd.Series([1, 2, 3], index=[\"A\", \"B\", \"C\"], name=\"values\")\n    transformer = LeftJoinTransformer([(\"foo\", lookup_df)])\n    transformer.fit_transform(X)\n    ```\n    ```\n      foo  foo_values\n    0   A           1\n    1   B           2\n    2   C           3\n    3   A           1\n    4   C           3\n    ```\n\n    Args:\n        features (List[Tuple[str, Union[pd.Series, pd.DataFrame]]]): A list of tuples\n            where the first element is the name of the column\n            and the second element is the look-up dataframe or series.\n    \"\"\"\n\n    __slots__ = (\"features\",)\n\n    def __init__(\n        self, features: List[Tuple[str, Union[pd.Series, pd.DataFrame]]]\n    ) -&gt; None:\n        super().__init__()\n        self.features = features\n\n    @staticmethod\n    def __prepare_lookup_df(\n        df: Union[pd.Series, pd.DataFrame], prefix: str\n    ) -&gt; pd.DataFrame:\n        if isinstance(df, pd.Series):\n            df.name = df.name if df.name else \"lookup\"\n            df = df.to_frame()\n\n        if df.index.name is None:\n            df.index.name = prefix\n\n        df.columns = [df.index.name + \"_\" + column for column in df.columns]\n\n        return df\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Perform a left-join on the given columns of a dataframe with another\n        cooresponding dataframe.\n\n        Args:\n            X (pd.DataFrame): Dataframe containing the columns to be joined on.\n\n        Returns:\n            pd.DataFrame: Dataframe joined on the given columns.\n        \"\"\"\n        X = check_ready_to_transform(\n            self,\n            X,\n            [feature[0] for feature in self.features],\n            force_all_finite=\"allow-nan\",\n            return_polars=True,\n        )\n\n        for column, lookup_df in self.features:\n            X = X.join(\n                pl.from_pandas(\n                    self.__prepare_lookup_df(lookup_df, column), include_index=True\n                ),\n                on=column,\n                how=\"left\",\n            )\n        return X.to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.LeftJoinTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Perform a left-join on the given columns of a dataframe with another cooresponding dataframe.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pd.DataFrame</code>  <p>Dataframe containing the columns to be joined on.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pd.DataFrame: Dataframe joined on the given columns.</p>     Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Perform a left-join on the given columns of a dataframe with another\n    cooresponding dataframe.\n\n    Args:\n        X (pd.DataFrame): Dataframe containing the columns to be joined on.\n\n    Returns:\n        pd.DataFrame: Dataframe joined on the given columns.\n    \"\"\"\n    X = check_ready_to_transform(\n        self,\n        X,\n        [feature[0] for feature in self.features],\n        force_all_finite=\"allow-nan\",\n        return_polars=True,\n    )\n\n    for column, lookup_df in self.features:\n        X = X.join(\n            pl.from_pandas(\n                self.__prepare_lookup_df(lookup_df, column), include_index=True\n            ),\n            on=column,\n            how=\"left\",\n        )\n    return X.to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.MapTransformer","title":"<code>MapTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>This transformer iterates over all columns in the <code>features</code> list and applies the given callback to the column.</p> <p>Internally this transformer uses Polars. You may encounter issues with your implementation. Please check the Polars documentation for more information: https://pola-rs.github.io/polars/py-polars/html/reference/</p> <p>Example: <pre><code>import pandas as pd\nfrom sk_transformers import MapTransformer\n\nX = pd.DataFrame({\"foo\": [1, 2, 3], \"bar\": [4, 5, 6]})\ntransformer = MapTransformer([(\"foo\", lambda x: x + 1)])\ntransformer.fit_transform(X)\n</code></pre> <pre><code>   foo  bar\n0    2    4\n1    3    5\n2    4    6\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>features</code>  <code>List[Tuple[str, Callable]]</code>  <p>List of tuples containing the name of the column to apply the callback on and the callback itself.</p>  required      Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>class MapTransformer(BaseTransformer):\n    \"\"\"This transformer iterates over all columns in the `features` list and\n    applies the given callback to the column.\n\n    Internally this transformer uses Polars. You may encounter issues with your implementation.\n    Please check the Polars documentation for more information:\n    https://pola-rs.github.io/polars/py-polars/html/reference/\n\n    Example:\n    ```python\n    import pandas as pd\n    from sk_transformers import MapTransformer\n\n    X = pd.DataFrame({\"foo\": [1, 2, 3], \"bar\": [4, 5, 6]})\n    transformer = MapTransformer([(\"foo\", lambda x: x + 1)])\n    transformer.fit_transform(X)\n    ```\n    ```\n       foo  bar\n    0    2    4\n    1    3    5\n    2    4    6\n    ```\n\n    Args:\n        features (List[Tuple[str, Callable]]): List of tuples containing the name of the\n            column to apply the callback on and the callback itself.\n    \"\"\"\n\n    def __init__(self, features: List[Tuple[str, Callable]]) -&gt; None:\n        super().__init__()\n        self.features = features\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Applies the callback to the column.\n\n        Args:\n            X (pandas.DataFrame): Dataframe containing the the columns to apply the callback on.\n\n        Returns:\n            pandas.DataFrame: The dataframe containing\n                the new column together with the non-transformed original columns.\n        \"\"\"\n        for _, func in self.features:\n            if isinstance(func, str) is False:\n                func = func.__name__  # type: ignore\n            if func == \"&lt;lambda&gt;\":  # type: ignore\n                warnings.warn(\n                    \"\"\"\n                        Internally this transformer uses Polars. You may encounter issues with your lambda implementations.\n                        Please check the documentation for correct syntax and functionality:\n                        https://pola-rs.github.io/polars-book/user-guide/dsl/custom_functions.html\n                        \"\"\",\n                    SyntaxWarning,\n                )\n\n        X = check_ready_to_transform(\n            self, X, [feature[0] for feature in self.features], return_polars=True\n        )\n\n        return X.with_columns(\n            [pl.col(column).map(callback) for column, callback in self.features]\n        ).to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.MapTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Applies the callback to the column.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pandas.DataFrame</code>  <p>Dataframe containing the the columns to apply the callback on.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pandas.DataFrame: The dataframe containing the new column together with the non-transformed original columns.</p>     Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Applies the callback to the column.\n\n    Args:\n        X (pandas.DataFrame): Dataframe containing the the columns to apply the callback on.\n\n    Returns:\n        pandas.DataFrame: The dataframe containing\n            the new column together with the non-transformed original columns.\n    \"\"\"\n    for _, func in self.features:\n        if isinstance(func, str) is False:\n            func = func.__name__  # type: ignore\n        if func == \"&lt;lambda&gt;\":  # type: ignore\n            warnings.warn(\n                \"\"\"\n                    Internally this transformer uses Polars. You may encounter issues with your lambda implementations.\n                    Please check the documentation for correct syntax and functionality:\n                    https://pola-rs.github.io/polars-book/user-guide/dsl/custom_functions.html\n                    \"\"\",\n                SyntaxWarning,\n            )\n\n    X = check_ready_to_transform(\n        self, X, [feature[0] for feature in self.features], return_polars=True\n    )\n\n    return X.with_columns(\n        [pl.col(column).map(callback) for column, callback in self.features]\n    ).to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.NaNTransformer","title":"<code>NaNTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>Replace NaN values with a specified value. Internally Pandas <code>fillna</code> method is used.</p> <p>Example: <pre><code>from sk_transformers import NaNTransformer\nimport pandas as pd\nimport numpy as np\n\nX = pd.DataFrame({\"foo\": [1, np.NaN, 3], \"bar\": [\"a\", np.NaN, \"c\"]})\ntransformer = NaNTransformer([(\"foo\", -999), (\"bar\", \"-999\")])\ntransformer.fit_transform(X)\n</code></pre> <pre><code>      foo   bar\n0     1.0     a\n1  -999.0  -999\n2     3.0     c\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>features</code>  <code>List[Tuple[str, Any]]</code>  <p>List of tuples where the first element is the column name, and the second is the value to replace NaN with.</p>  required     <p>Raises:</p>    Type Description      <code>TypeError</code>  <p>If the value to replace NaN with is not a number, but the column is a number or vice versa.</p>     Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>class NaNTransformer(BaseTransformer):\n    \"\"\"Replace NaN values with a specified value. Internally Pandas [`fillna`](\n    https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html)\n    method is used.\n\n    Example:\n    ```python\n    from sk_transformers import NaNTransformer\n    import pandas as pd\n    import numpy as np\n\n    X = pd.DataFrame({\"foo\": [1, np.NaN, 3], \"bar\": [\"a\", np.NaN, \"c\"]})\n    transformer = NaNTransformer([(\"foo\", -999), (\"bar\", \"-999\")])\n    transformer.fit_transform(X)\n    ```\n    ```\n          foo   bar\n    0     1.0     a\n    1  -999.0  -999\n    2     3.0     c\n    ```\n\n    Args:\n        features (List[Tuple[str, Any]]): List of tuples where the first element is the column name, and the second is the value to replace NaN with.\n\n    Raises:\n        TypeError: If the value to replace NaN with is not a number, but the column is a number or vice versa.\n    \"\"\"\n\n    def __init__(self, features: List[Tuple[str, Any]]) -&gt; None:\n        super().__init__()\n        self.features = features\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Replace NaN values with a specified value.\n\n        Args:\n            X (pandas.DataFrame): Dataframe to transform.\n\n        Returns:\n            pandas.DataFrame: Transformed dataframe.\n        \"\"\"\n        X = check_ready_to_transform(\n            self,\n            X,\n            [feature[0] for feature in self.features],\n            force_all_finite=\"allow-nan\",\n            return_polars=True,\n        )\n\n        feature_dict = dict(self.features)\n        select_expr = []\n        for feature in X.columns:\n            if feature in feature_dict.keys():\n                select_expr.append(pl.col(feature).fill_null(feature_dict[feature]))\n            else:\n                select_expr.append(pl.col(feature))\n        return X.select(select_expr).to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.NaNTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Replace NaN values with a specified value.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pandas.DataFrame</code>  <p>Dataframe to transform.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pandas.DataFrame: Transformed dataframe.</p>     Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Replace NaN values with a specified value.\n\n    Args:\n        X (pandas.DataFrame): Dataframe to transform.\n\n    Returns:\n        pandas.DataFrame: Transformed dataframe.\n    \"\"\"\n    X = check_ready_to_transform(\n        self,\n        X,\n        [feature[0] for feature in self.features],\n        force_all_finite=\"allow-nan\",\n        return_polars=True,\n    )\n\n    feature_dict = dict(self.features)\n    select_expr = []\n    for feature in X.columns:\n        if feature in feature_dict.keys():\n            select_expr.append(pl.col(feature).fill_null(feature_dict[feature]))\n        else:\n            select_expr.append(pl.col(feature))\n    return X.select(select_expr).to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.QueryTransformer","title":"<code>QueryTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>Applies a list of queries to a dataframe. If it operates on a dataset used for supervised learning this transformer should be applied on the dataframe containing <code>X</code> and <code>y</code>. So removing of columns by queries also removes the corresponding <code>y</code> value.</p> <p>Example: <pre><code>import pandas as pd\nfrom sk_transformers import QueryTransformer\n\nX = pd.DataFrame({\"foo\": [1, 8, 3, 6, 5, 4, 7, 2]})\ntransformer = QueryTransformer([\"foo &gt; 4\"])\ntransformer.fit_transform(X)\n</code></pre> <pre><code>   foo\n1    8\n3    6\n4    5\n6    7\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>queries</code>  <code>List[str]</code>  <p>List of query string to evaluate to the dataframe.</p>  required      Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>class QueryTransformer(BaseTransformer):\n    \"\"\"Applies a list of queries to a dataframe. If it operates on a dataset\n    used for supervised learning this transformer should be applied on the\n    dataframe containing `X` and `y`. So removing of columns by queries also\n    removes the corresponding `y` value.\n\n    Example:\n    ```python\n    import pandas as pd\n    from sk_transformers import QueryTransformer\n\n    X = pd.DataFrame({\"foo\": [1, 8, 3, 6, 5, 4, 7, 2]})\n    transformer = QueryTransformer([\"foo &gt; 4\"])\n    transformer.fit_transform(X)\n    ```\n    ```\n       foo\n    1    8\n    3    6\n    4    5\n    6    7\n    ```\n\n    Args:\n        queries (List[str]): List of query string to evaluate to the dataframe.\n    \"\"\"\n\n    def __init__(self, queries: List[str]) -&gt; None:\n        super().__init__()\n        self.queries = queries\n\n    def transform(self, Xy: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Applies the list of queries to the dataframe.\n\n        Args:\n            Xy (pd.DataFrame): Dataframe to apply the queries to. For also operating on the target column `y` - if needed.\n                This column should also be part of the dataframe.\n\n        Returns:\n            pd.DataFrame: Dataframe with the queries applied.\n        \"\"\"\n        Xy = check_ready_to_transform(\n            self, Xy, Xy.columns, force_all_finite=\"allow-nan\"\n        )\n        for query in self.queries:\n            Xy = Xy.query(query, inplace=False)\n        return Xy\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.QueryTransformer.transform","title":"<code>transform(Xy)</code>","text":"<p>Applies the list of queries to the dataframe.</p> <p>Parameters:</p>    Name Type Description Default     <code>Xy</code>  <code>pd.DataFrame</code>  <p>Dataframe to apply the queries to. For also operating on the target column <code>y</code> - if needed. This column should also be part of the dataframe.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pd.DataFrame: Dataframe with the queries applied.</p>     Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>def transform(self, Xy: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Applies the list of queries to the dataframe.\n\n    Args:\n        Xy (pd.DataFrame): Dataframe to apply the queries to. For also operating on the target column `y` - if needed.\n            This column should also be part of the dataframe.\n\n    Returns:\n        pd.DataFrame: Dataframe with the queries applied.\n    \"\"\"\n    Xy = check_ready_to_transform(\n        self, Xy, Xy.columns, force_all_finite=\"allow-nan\"\n    )\n    for query in self.queries:\n        Xy = Xy.query(query, inplace=False)\n    return Xy\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.ValueIndicatorTransformer","title":"<code>ValueIndicatorTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>Adds a column to a dataframe indicating if a value is equal to a specified value. The idea behind this method is, that it is often useful to know if a <code>NaN</code> value was present in the original data and has been changed by some imputation step. Sometimes the present of a <code>NaN</code> value is actually important information. But obviously this method works with any kind of data.</p> <p><code>NaN</code>, <code>None</code> or <code>np.nan</code> are Not caught by this implementation.</p> <p>Example: <pre><code>from sk_transformers import ValueIndicatorTransformer\nimport pandas as pd\n\nX = pd.DataFrame({\"foo\": [1, -999, 3], \"bar\": [\"a\", \"-999\", \"c\"]})\ntransformer = ValueIndicatorTransformer([(\"foo\", -999), (\"bar\", \"-999\")])\ntransformer.fit_transform(X).to_dict()\n</code></pre> <pre><code>   foo   bar  foo_found_indicator  bar_found_indicator\n0    1     a                False                False\n1 -999  -999                 True                 True\n2    3     c                False                False\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>features</code>  <code>List[Tuple[str, Any]]</code>  <p>A list of tuples where the first value in represents the column name and the second value represents the value to check for.</p>  required      Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>class ValueIndicatorTransformer(BaseTransformer):\n    \"\"\"Adds a column to a dataframe indicating if a value is equal to a\n    specified value. The idea behind this method is, that it is often useful to\n    know if a `NaN` value was present in the original data and has been changed\n    by some imputation step. Sometimes the present of a `NaN` value is actually\n    important information. But obviously this method works with any kind of\n    data.\n\n    `NaN`, `None` or `np.nan` are **Not** caught by this implementation.\n\n    Example:\n    ```python\n    from sk_transformers import ValueIndicatorTransformer\n    import pandas as pd\n\n    X = pd.DataFrame({\"foo\": [1, -999, 3], \"bar\": [\"a\", \"-999\", \"c\"]})\n    transformer = ValueIndicatorTransformer([(\"foo\", -999), (\"bar\", \"-999\")])\n    transformer.fit_transform(X).to_dict()\n    ```\n    ```\n       foo   bar  foo_found_indicator  bar_found_indicator\n    0    1     a                False                False\n    1 -999  -999                 True                 True\n    2    3     c                False                False\n    ```\n\n    Args:\n        features (List[Tuple[str, Any]]): A list of tuples where the first value in represents the column\n            name and the second value represents the value to check for.\n    \"\"\"\n\n    def __init__(self, features: List[Tuple[str, Any]], as_int: bool = False) -&gt; None:\n        super().__init__()\n        self.features = features\n        self.as_int = as_int\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Add a column to a dataframe indicating if a value is equal to a\n        specified value.\n\n        Args:\n            X (pandas.DataFrame): Dataframe to transform.\n\n        Returns:\n            pandas.DataFrame: Transformed dataframe containing columns indicating if a certain value was found.\n                Format of the new columns: `\"column_name\"_nan_indicator`.\n        \"\"\"\n        X = check_ready_to_transform(\n            self,\n            X,\n            [feature[0] for feature in self.features],\n            force_all_finite=\"allow-nan\",\n            return_polars=True,\n        )\n\n        return X.with_columns(\n            [\n                (pl.col(column) == indicator)\n                .cast(pl.Int32 if self.as_int else pl.Boolean)\n                .suffix(\"_found_indicator\")\n                for column, indicator in self.features\n            ]\n        ).to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.ValueIndicatorTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Add a column to a dataframe indicating if a value is equal to a specified value.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pandas.DataFrame</code>  <p>Dataframe to transform.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pandas.DataFrame: Transformed dataframe containing columns indicating if a certain value was found. Format of the new columns: <code>\"column_name\"_nan_indicator</code>.</p>     Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Add a column to a dataframe indicating if a value is equal to a\n    specified value.\n\n    Args:\n        X (pandas.DataFrame): Dataframe to transform.\n\n    Returns:\n        pandas.DataFrame: Transformed dataframe containing columns indicating if a certain value was found.\n            Format of the new columns: `\"column_name\"_nan_indicator`.\n    \"\"\"\n    X = check_ready_to_transform(\n        self,\n        X,\n        [feature[0] for feature in self.features],\n        force_all_finite=\"allow-nan\",\n        return_polars=True,\n    )\n\n    return X.with_columns(\n        [\n            (pl.col(column) == indicator)\n            .cast(pl.Int32 if self.as_int else pl.Boolean)\n            .suffix(\"_found_indicator\")\n            for column, indicator in self.features\n        ]\n    ).to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.ValueReplacerTransformer","title":"<code>ValueReplacerTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>Uses Pandas <code>replace</code> method to replace values in a column. This transformer loops over the <code>features</code> and applies <code>replace</code> to the according columns. If the column is not from type string but a valid regular expression is provided the column will be temporarily changed to a string column and after the manipulation by <code>replace</code> changed back to its original type. It may happen, that this type changing fails if the modified column is not compatible with its original type.</p> <p>Example: <pre><code>import pandas as pd\nfrom sk_transformers import ValueReplacerTransformer\n\nX = pd.DataFrame(\n    {\"foo\": [\"0000-01-01\", \"2022/01/08\", \"bar\", \"1982-12-7\", \"28-09-2022\"]}\n)\ntransformer = ValueReplacerTransformer(\n    [\n        (\n            [\"foo\"],\n            r\"^(?!(19|20)\\d\\d[-\\/.](0[1-9]|1[012]|[1-9])[-\\/.](0[1-9]|[12][0-9]|3[01]|[1-9])$).*\",\n            \"1900-01-01\",\n        )\n    ]\n)\n\ntransformer.fit_transform(X)\n</code></pre> <pre><code>          foo\n0  1900-01-01\n1  2022/01/08\n2  1900-01-01\n3   1982-12-7\n4  1900-01-01\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>features</code>  <code>List[Tuple[List[str], str, Any]]</code>  <p>List of tuples containing the column names as a list, the value to replace (can be a regex), and the replacement value.</p>  required      Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>class ValueReplacerTransformer(BaseTransformer):\n    r\"\"\"Uses Pandas `replace` method to replace values in a column. This\n    transformer loops over the `features` and applies `replace` to the\n    according columns. If the column is not from type string but a valid\n    regular expression is provided the column will be temporarily changed to a\n    string column and after the manipulation by `replace` changed back to its\n    original type. It may happen, that this type changing fails if the modified\n    column is not compatible with its original type.\n\n    Example:\n    ```python\n    import pandas as pd\n    from sk_transformers import ValueReplacerTransformer\n\n    X = pd.DataFrame(\n        {\"foo\": [\"0000-01-01\", \"2022/01/08\", \"bar\", \"1982-12-7\", \"28-09-2022\"]}\n    )\n    transformer = ValueReplacerTransformer(\n        [\n            (\n                [\"foo\"],\n                r\"^(?!(19|20)\\d\\d[-\\/.](0[1-9]|1[012]|[1-9])[-\\/.](0[1-9]|[12][0-9]|3[01]|[1-9])$).*\",\n                \"1900-01-01\",\n            )\n        ]\n    )\n\n    transformer.fit_transform(X)\n    ```\n    ```\n              foo\n    0  1900-01-01\n    1  2022/01/08\n    2  1900-01-01\n    3   1982-12-7\n    4  1900-01-01\n    ```\n\n    Args:\n        features (List[Tuple[List[str], str, Any]]): List of tuples containing the column names as a list,\n            the value to replace (can be a regex), and the replacement value.\n    \"\"\"\n\n    def __init__(self, features: List[Tuple[List[str], Any, Any]]) -&gt; None:\n        super().__init__()\n        self.features = features\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Replaces a value or regular expression with another value.\n\n        Args:\n            X (pd.DataFrame): Dataframe containing the columns where values should be replaced.\n\n        Returns:\n            pd.DataFrame: Dataframe with replaced values.\n        \"\"\"\n        X = check_ready_to_transform(\n            self, X, [feature[0][0] for feature in self.features]\n        )\n\n        for columns, value, replacement in self.features:\n            for column in columns:\n                is_regex = ValueReplacerTransformer.__check_for_regex(value)\n                column_dtype = X[column].dtype\n\n                if column_dtype is not str and is_regex:\n                    X[column] = X[column].astype(str)\n\n                X[column] = X[column].replace(value, replacement, regex=is_regex)\n\n                if X[column].dtype != column_dtype:\n                    X[column] = X[column].astype(column_dtype)\n\n        return X\n\n    @staticmethod\n    def __check_for_regex(value: Any) -&gt; bool:\n        if not isinstance(value, str):\n            return False\n        try:\n            re.compile(value)\n            is_valid = True\n        except re.error:\n            is_valid = False\n        return is_valid\n</code></pre>"},{"location":"API-reference/transformer/generic_transformer/#sk_transformers.generic_transformer.ValueReplacerTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Replaces a value or regular expression with another value.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pd.DataFrame</code>  <p>Dataframe containing the columns where values should be replaced.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pd.DataFrame: Dataframe with replaced values.</p>     Source code in <code>src/sk_transformers/generic_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Replaces a value or regular expression with another value.\n\n    Args:\n        X (pd.DataFrame): Dataframe containing the columns where values should be replaced.\n\n    Returns:\n        pd.DataFrame: Dataframe with replaced values.\n    \"\"\"\n    X = check_ready_to_transform(\n        self, X, [feature[0][0] for feature in self.features]\n    )\n\n    for columns, value, replacement in self.features:\n        for column in columns:\n            is_regex = ValueReplacerTransformer.__check_for_regex(value)\n            column_dtype = X[column].dtype\n\n            if column_dtype is not str and is_regex:\n                X[column] = X[column].astype(str)\n\n            X[column] = X[column].replace(value, replacement, regex=is_regex)\n\n            if X[column].dtype != column_dtype:\n                X[column] = X[column].astype(column_dtype)\n\n    return X\n</code></pre>"},{"location":"API-reference/transformer/number_transformer/","title":"Number transformer","text":""},{"location":"API-reference/transformer/number_transformer/#sk_transformers.number_transformer.GeoDistanceTransformer","title":"<code>GeoDistanceTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>Calculates the distance in kilometers between two places on the earth using the geographic coordinates.</p> <p>Example: <pre><code>import pandas as pd\nfrom sk_transformers import GeoDistanceTransformer\n\nX = pd.DataFrame(\n    {\n        \"lat_1\": [48.353802, 51.289501, 53.63040161],\n        \"long_1\": [11.7861, 6.76678, 9.988229752],\n        \"lat_2\": [51.289501, 53.63040161, 48.353802],\n        \"long_2\": [6.76678, 9.988229752, 11.7861],\n    }\n)\ntransformer = GeoDistanceTransformer([(\"lat_1\", \"long_1\", \"lat_2\", \"long_2\")])\ntransformer.fit_transform(X)\n</code></pre> <pre><code>       lat_1    long_1      lat_2    long_2  distance_lat_1_lat_2\n0  48.353802  11.78610  51.289501   6.76678            485.975293\n1  51.289501   6.76678  53.630402   9.98823            339.730537\n2  53.630402   9.98823  48.353802  11.78610            600.208154\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>features</code>  <code>List[Tuple[str, str, str, str]]</code>  <p>A list of tuples containing the names of four columns, which are coordinates of the two points in the following order: - latitude of point 1 - longitude of point 1 - latitude of point 2 - longitude of point 2</p>  required      Source code in <code>src/sk_transformers/number_transformer.py</code> <pre><code>class GeoDistanceTransformer(BaseTransformer):\n    \"\"\"Calculates the distance in kilometers between two places on the earth\n    using the geographic coordinates.\n\n    Example:\n    ```python\n    import pandas as pd\n    from sk_transformers import GeoDistanceTransformer\n\n    X = pd.DataFrame(\n        {\n            \"lat_1\": [48.353802, 51.289501, 53.63040161],\n            \"long_1\": [11.7861, 6.76678, 9.988229752],\n            \"lat_2\": [51.289501, 53.63040161, 48.353802],\n            \"long_2\": [6.76678, 9.988229752, 11.7861],\n        }\n    )\n    transformer = GeoDistanceTransformer([(\"lat_1\", \"long_1\", \"lat_2\", \"long_2\")])\n    transformer.fit_transform(X)\n    ```\n    ```\n           lat_1    long_1      lat_2    long_2  distance_lat_1_lat_2\n    0  48.353802  11.78610  51.289501   6.76678            485.975293\n    1  51.289501   6.76678  53.630402   9.98823            339.730537\n    2  53.630402   9.98823  48.353802  11.78610            600.208154\n    ```\n\n    Args:\n        features: A list of tuples containing the names of four columns, which are coordinates of the\n            two points in the following order:\n            - latitude of point 1\n            - longitude of point 1\n            - latitude of point 2\n            - longitude of point 2\n    \"\"\"\n\n    def __init__(self, features: List[Tuple[str, str, str, str]]) -&gt; None:\n        super().__init__()\n        self.features = features\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Adds new columns containing the distances between two points on the\n        earth based on their geographical coordinates.\n\n        Args:\n            X (pandas.DataFrame): Dataframe containing the coordinates of the two points as four columns.\n\n        Returns:\n            pandas.DataFrame: Dataframe containing the new columns.\n        \"\"\"\n        X = check_ready_to_transform(self, X, [feature[0] for feature in self.features])\n\n        for coordinates in self.features:\n            GeoDistanceTransformer.__check_latitudes(X[coordinates[0]])\n            GeoDistanceTransformer.__check_longitudes(X[coordinates[1]])\n            GeoDistanceTransformer.__check_latitudes(X[coordinates[2]])\n            GeoDistanceTransformer.__check_longitudes(X[coordinates[3]])\n\n            X[f\"distance_{coordinates[0]}_{coordinates[2]}\"] = pd.Series(\n                GeoDistanceTransformer.__distance_function(\n                    X[coordinates[0]].to_numpy(),\n                    X[coordinates[1]].to_numpy(),\n                    X[coordinates[2]].to_numpy(),\n                    X[coordinates[3]].to_numpy(),\n                )\n            )\n\n        return X\n\n    @staticmethod\n    def __distance_function(\n        latitude_1: NDArray,\n        longitude_1: NDArray,\n        latitude_2: NDArray,\n        longitude_2: NDArray,\n    ) -&gt; NDArray:\n        \"\"\"Calculates the distance (in kilometer) between two points on the\n        earth.\n\n        Args:\n            latitude_1 (NDArray): Latitude of the first point.\n            longitude_1 (NDArray): Longitude of the first point.\n            latitude_2 (NDArray): Latitude of the second point.\n            longitude_2 (NDArray): Longitude of the second point.\n\n        Returns:\n            NDArray[numpy.float16]: Distance between the two points in kilometer.\n        \"\"\"\n\n        latitude_1_radians = np.radians(latitude_1)\n        longitude_1_radians = np.radians(longitude_1)\n        latitude_2_radians = np.radians(latitude_2)\n        longitude_2_radians = np.radians(longitude_2)\n\n        diff_latitude = latitude_2_radians - latitude_1_radians\n        diff_longitude = longitude_2_radians - longitude_1_radians\n\n        return (\n            2\n            * 6373\n            * np.arcsin(\n                np.sqrt(\n                    np.sin(diff_latitude / 2) ** 2\n                    + np.cos(latitude_1_radians)\n                    * np.cos(latitude_2_radians)\n                    * np.sin(diff_longitude / 2) ** 2\n                )\n            )\n        )\n\n    @staticmethod\n    def __check_latitudes(x: pd.Series) -&gt; None:\n        if ((x &gt; 90) | (x &lt; -90)).sum() &gt; 0:\n            raise ValueError(\"Invalid values for latitude.\")\n\n    @staticmethod\n    def __check_longitudes(x: pd.Series) -&gt; None:\n        if ((x &gt; 180) | (x &lt; -180)).sum() &gt; 0:\n            raise ValueError(\"Invalid values for longitude.\")\n</code></pre>"},{"location":"API-reference/transformer/number_transformer/#sk_transformers.number_transformer.GeoDistanceTransformer.__distance_function","title":"<code>__distance_function(latitude_1, longitude_1, latitude_2, longitude_2)</code>  <code>staticmethod</code>","text":"<p>Calculates the distance (in kilometer) between two points on the earth.</p> <p>Parameters:</p>    Name Type Description Default     <code>latitude_1</code>  <code>NDArray</code>  <p>Latitude of the first point.</p>  required    <code>longitude_1</code>  <code>NDArray</code>  <p>Longitude of the first point.</p>  required    <code>latitude_2</code>  <code>NDArray</code>  <p>Latitude of the second point.</p>  required    <code>longitude_2</code>  <code>NDArray</code>  <p>Longitude of the second point.</p>  required     <p>Returns:</p>    Type Description      <code>NDArray</code>  <p>NDArray[numpy.float16]: Distance between the two points in kilometer.</p>     Source code in <code>src/sk_transformers/number_transformer.py</code> <pre><code>@staticmethod\ndef __distance_function(\n    latitude_1: NDArray,\n    longitude_1: NDArray,\n    latitude_2: NDArray,\n    longitude_2: NDArray,\n) -&gt; NDArray:\n    \"\"\"Calculates the distance (in kilometer) between two points on the\n    earth.\n\n    Args:\n        latitude_1 (NDArray): Latitude of the first point.\n        longitude_1 (NDArray): Longitude of the first point.\n        latitude_2 (NDArray): Latitude of the second point.\n        longitude_2 (NDArray): Longitude of the second point.\n\n    Returns:\n        NDArray[numpy.float16]: Distance between the two points in kilometer.\n    \"\"\"\n\n    latitude_1_radians = np.radians(latitude_1)\n    longitude_1_radians = np.radians(longitude_1)\n    latitude_2_radians = np.radians(latitude_2)\n    longitude_2_radians = np.radians(longitude_2)\n\n    diff_latitude = latitude_2_radians - latitude_1_radians\n    diff_longitude = longitude_2_radians - longitude_1_radians\n\n    return (\n        2\n        * 6373\n        * np.arcsin(\n            np.sqrt(\n                np.sin(diff_latitude / 2) ** 2\n                + np.cos(latitude_1_radians)\n                * np.cos(latitude_2_radians)\n                * np.sin(diff_longitude / 2) ** 2\n            )\n        )\n    )\n</code></pre>"},{"location":"API-reference/transformer/number_transformer/#sk_transformers.number_transformer.GeoDistanceTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Adds new columns containing the distances between two points on the earth based on their geographical coordinates.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pandas.DataFrame</code>  <p>Dataframe containing the coordinates of the two points as four columns.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pandas.DataFrame: Dataframe containing the new columns.</p>     Source code in <code>src/sk_transformers/number_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Adds new columns containing the distances between two points on the\n    earth based on their geographical coordinates.\n\n    Args:\n        X (pandas.DataFrame): Dataframe containing the coordinates of the two points as four columns.\n\n    Returns:\n        pandas.DataFrame: Dataframe containing the new columns.\n    \"\"\"\n    X = check_ready_to_transform(self, X, [feature[0] for feature in self.features])\n\n    for coordinates in self.features:\n        GeoDistanceTransformer.__check_latitudes(X[coordinates[0]])\n        GeoDistanceTransformer.__check_longitudes(X[coordinates[1]])\n        GeoDistanceTransformer.__check_latitudes(X[coordinates[2]])\n        GeoDistanceTransformer.__check_longitudes(X[coordinates[3]])\n\n        X[f\"distance_{coordinates[0]}_{coordinates[2]}\"] = pd.Series(\n            GeoDistanceTransformer.__distance_function(\n                X[coordinates[0]].to_numpy(),\n                X[coordinates[1]].to_numpy(),\n                X[coordinates[2]].to_numpy(),\n                X[coordinates[3]].to_numpy(),\n            )\n        )\n\n    return X\n</code></pre>"},{"location":"API-reference/transformer/number_transformer/#sk_transformers.number_transformer.MathExpressionTransformer","title":"<code>MathExpressionTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>Applies an function/operation to a column and a given value or column. The operation can be a function from NumPy's mathematical functions or operator package.</p> <p>Warning! Some functions/operators may not work as expected. Especially, functions that don't belong in <code>numpy.ufunc</code> are not supported. NumPy functions with return values that don't fit the size of the source column are also not supported.</p> <p>Example: <pre><code>import pandas as pd\nfrom sk_transformers import MathExpressionTransformer\n\nX = pd.DataFrame({\"foo\": [1, 2, 3], \"bar\": [4, 5, 6]})\ntransformer = MathExpressionTransformer([(\"foo\", \"np.add\", \"bar\", None)])\ntransformer.fit_transform(X)\n</code></pre> <pre><code>   foo  bar  foo_add_bar\n0    1    4            5\n1    2    5            7\n2    3    6            9\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>features</code>  <code>List[str, str, Union[int, float]]</code>  <p>List of tuples containing the name of the column to apply the operation on, a string representation of the operation (see list above) and the value to apply the operation on. The value can be an number (int or float) or the name of another column in the dataframe. If the value is <code>None</code>, it it expected that the operation only takes one argument. The fourth entry of the tuple is a dictionary passed as <code>kwargs</code> to the operation.</p>  required      Source code in <code>src/sk_transformers/number_transformer.py</code> <pre><code>class MathExpressionTransformer(BaseTransformer):\n    \"\"\"Applies an function/operation to a column and a given value or column.\n    The operation can be a function from NumPy's mathematical functions or\n    operator package.\n\n    **Warning!** Some functions/operators may not work as expected. Especially, functions that don't\n    belong in [`numpy.ufunc`](https://numpy.org/doc/stable/reference/ufuncs.html) are not supported.\n    NumPy functions with return values that don't fit the size of the source column are also not supported.\n\n    Example:\n    ```python\n    import pandas as pd\n    from sk_transformers import MathExpressionTransformer\n\n    X = pd.DataFrame({\"foo\": [1, 2, 3], \"bar\": [4, 5, 6]})\n    transformer = MathExpressionTransformer([(\"foo\", \"np.add\", \"bar\", None)])\n    transformer.fit_transform(X)\n    ```\n    ```\n       foo  bar  foo_add_bar\n    0    1    4            5\n    1    2    5            7\n    2    3    6            9\n    ```\n\n    Args:\n        features (List[str, str, Union[int, float]]): List of tuples containing the name of the column to apply the operation on,\n            a string representation of the operation (see list above) and the value to apply the operation on. The value can be\n            an number (int or float) or the name of another column in the dataframe. If the value is `None`, it it expected that\n            the operation only takes one argument. The fourth entry of the tuple is a dictionary passed as `kwargs` to the operation.\n    \"\"\"\n\n    def __init__(\n        self,\n        features: List[\n            Tuple[str, str, Union[int, float, str, None], Optional[Dict[str, Any]]]\n        ],\n    ) -&gt; None:\n        super().__init__()\n        self.features = features\n\n    def __verify_operation(self, operation: str) -&gt; Tuple[bool, Any]:\n        if operation.startswith(\"np\"):\n            if hasattr(np, operation[3:]):\n                op = getattr(np, operation[3:])\n                is_np_op = True\n                if not isinstance(op, np.ufunc):\n                    raise ValueError(\n                        f\"The function `{operation}` is not a NumPy universal function. If you are using `np.sum` or `np.prod`, please use `np.add` or `np.multiply` instead.\"\n                    )\n            else:\n                raise AttributeError(f\"Operation {operation[3:]} not found in NumPy!\")\n\n        elif hasattr(operator, operation) and operation not in [\n            \"attrgetter\",\n            \"itemgetter\",\n            \"methodcaller\",\n        ]:\n            op = getattr(operator, operation)\n            is_np_op = False\n\n        else:\n            raise AttributeError(\n                f\"Invalid operation! `{operation}` is not a valid operation! Please refer to the `numpy` and `operator` package.\"\n            )\n\n        return is_np_op, op\n\n    def __abbreviate_numpy_in_operation(self, operation: str) -&gt; str:\n        \"\"\"Replaces `numpy` at the start of a string with `np`.\n\n        Args:\n            operation (str): The operation as a string.\n\n        Returns:\n            str: The operation as a string with numpy replaced with np.\n        \"\"\"\n        if operation.startswith(\"numpy\"):\n            operation = \"np\" + operation[5:]\n        return operation\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Applies the operation to the column and the value.\n\n        Args:\n            X (pandas.DataFrame): DataFrame containing the columns to apply the operation on.\n\n        Returns:\n            pandas.DataFrame: The original dataframe with the new columns. The new columns are named as follows:\n            '`column_name`_`operation`_`value`' or '`column_name`_`operation`' if `value` is `None`.\n        \"\"\"\n        X = check_ready_to_transform(self, X, [feature[0] for feature in self.features])\n\n        for feature, operation, value, kwargs in self.features:\n            operation = self.__abbreviate_numpy_in_operation(operation)\n            is_np_op, op = self.__verify_operation(operation)\n\n            new_column = f\"{feature}_{operation}\".replace(\"np.\", \"\")\n            new_column_with_value = f\"{feature}_{operation}_{value}\".replace(\"np.\", \"\")\n\n            if is_np_op:\n                warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n                if value is None:\n                    X[new_column] = op(X[feature], **kwargs or {})\n                elif isinstance(value, str):\n                    X[new_column_with_value] = op(X[feature], X[value], **kwargs or {})\n                else:\n                    X[new_column_with_value] = op(X[feature], value, **kwargs or {})\n            else:\n                if value is None:\n                    X[new_column] = op(X[feature])\n                elif isinstance(value, str):\n                    X[new_column_with_value] = op(X[feature], X[value])\n                else:\n                    X[new_column_with_value] = op(\n                        X[feature], value\n                    )  # This created a ragged array in will be deprecated in future.\n        return X\n</code></pre>"},{"location":"API-reference/transformer/number_transformer/#sk_transformers.number_transformer.MathExpressionTransformer.__abbreviate_numpy_in_operation","title":"<code>__abbreviate_numpy_in_operation(operation)</code>","text":"<p>Replaces <code>numpy</code> at the start of a string with <code>np</code>.</p> <p>Parameters:</p>    Name Type Description Default     <code>operation</code>  <code>str</code>  <p>The operation as a string.</p>  required     <p>Returns:</p>    Name Type Description     <code>str</code>  <code>str</code>  <p>The operation as a string with numpy replaced with np.</p>     Source code in <code>src/sk_transformers/number_transformer.py</code> <pre><code>def __abbreviate_numpy_in_operation(self, operation: str) -&gt; str:\n    \"\"\"Replaces `numpy` at the start of a string with `np`.\n\n    Args:\n        operation (str): The operation as a string.\n\n    Returns:\n        str: The operation as a string with numpy replaced with np.\n    \"\"\"\n    if operation.startswith(\"numpy\"):\n        operation = \"np\" + operation[5:]\n    return operation\n</code></pre>"},{"location":"API-reference/transformer/number_transformer/#sk_transformers.number_transformer.MathExpressionTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Applies the operation to the column and the value.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pandas.DataFrame</code>  <p>DataFrame containing the columns to apply the operation on.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pandas.DataFrame: The original dataframe with the new columns. The new columns are named as follows:</p>    <code>pd.DataFrame</code>  <p>'<code>column_name</code><code>operation</code><code>value</code>' or '<code>column_name</code>_<code>operation</code>' if <code>value</code> is <code>None</code>.</p>     Source code in <code>src/sk_transformers/number_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Applies the operation to the column and the value.\n\n    Args:\n        X (pandas.DataFrame): DataFrame containing the columns to apply the operation on.\n\n    Returns:\n        pandas.DataFrame: The original dataframe with the new columns. The new columns are named as follows:\n        '`column_name`_`operation`_`value`' or '`column_name`_`operation`' if `value` is `None`.\n    \"\"\"\n    X = check_ready_to_transform(self, X, [feature[0] for feature in self.features])\n\n    for feature, operation, value, kwargs in self.features:\n        operation = self.__abbreviate_numpy_in_operation(operation)\n        is_np_op, op = self.__verify_operation(operation)\n\n        new_column = f\"{feature}_{operation}\".replace(\"np.\", \"\")\n        new_column_with_value = f\"{feature}_{operation}_{value}\".replace(\"np.\", \"\")\n\n        if is_np_op:\n            warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n            if value is None:\n                X[new_column] = op(X[feature], **kwargs or {})\n            elif isinstance(value, str):\n                X[new_column_with_value] = op(X[feature], X[value], **kwargs or {})\n            else:\n                X[new_column_with_value] = op(X[feature], value, **kwargs or {})\n        else:\n            if value is None:\n                X[new_column] = op(X[feature])\n            elif isinstance(value, str):\n                X[new_column_with_value] = op(X[feature], X[value])\n            else:\n                X[new_column_with_value] = op(\n                    X[feature], value\n                )  # This created a ragged array in will be deprecated in future.\n    return X\n</code></pre>"},{"location":"API-reference/transformer/string_transformer/","title":"String transformer","text":""},{"location":"API-reference/transformer/string_transformer/#sk_transformers.string_transformer.EmailTransformer","title":"<code>EmailTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>Transforms an email address into multiple features.</p> <p>Example: <pre><code>import pandas as pd\nfrom sk_transformers import EmailTransformer\n\nX = pd.DataFrame({\"foo\": [\"person-123@test.com\"]})\ntransformer = EmailTransformer([\"foo\"])\ntransformer.fit_transform(X)\n</code></pre> <pre><code>          foo foo_domain  foo_num_of_digits  foo_num_of_letters      0  person-123       test                  3                   6\n\nfoo_num_of_special_chars  foo_num_of_repeated_chars  foo_num_of_words\n0                         1                          1                 2\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>features</code>  <code>List[str]</code>  <p>List of features which should be transformed.</p>  required      Source code in <code>src/sk_transformers/string_transformer.py</code> <pre><code>class EmailTransformer(BaseTransformer):\n    \"\"\"Transforms an email address into multiple features.\n\n    Example:\n    ```python\n    import pandas as pd\n    from sk_transformers import EmailTransformer\n\n    X = pd.DataFrame({\"foo\": [\"person-123@test.com\"]})\n    transformer = EmailTransformer([\"foo\"])\n    transformer.fit_transform(X)\n    ```\n    ```\n              foo foo_domain  foo_num_of_digits  foo_num_of_letters  \\\n    0  person-123       test                  3                   6\n\n    foo_num_of_special_chars  foo_num_of_repeated_chars  foo_num_of_words\n    0                         1                          1                 2\n    ```\n\n    Args:\n        features (List[str]): List of features which should be transformed.\n    \"\"\"\n\n    def __init__(self, features: List[str]) -&gt; None:\n        super().__init__()\n        self.features = features\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Transforms the one column from X, containing the email addresses,\n        into multiple columns.\n\n        Args:\n            X (pandas.DataFrame): DataFrame to transform.\n\n        Returns:\n            pandas.DataFrame: Transformed dataframe containing the extra columns.\n        \"\"\"\n        X = check_ready_to_transform(self, X, self.features, return_polars=True)\n\n        for column in self.features:  # pylint: disable=duplicate-code\n            X = X.with_columns(\n                pl.col(column)\n                .str.split_exact(\"@\", 1)\n                .struct.rename_fields([\"username\", \"domain\"])\n                .alias(\"email_parts\"),\n            ).unnest(\"email_parts\")\n\n            X = (\n                X.with_columns(\n                    pl.col(\"domain\")\n                    .str.split_exact(\".\", 1)\n                    .struct.rename_fields([f\"{column}_domain\", \"subdomain\"])\n                    .alias(\"domain_parts\"),\n                )\n                .unnest(\"domain_parts\")\n                .drop([\"domain\", \"subdomain\"])\n            )\n\n            expr = [\n                pl.col(\"username\")\n                .str.count_match(r\"\\d\")\n                .cast(pl.Int64)\n                .alias(f\"{column}_num_of_digits\"),\n                pl.col(\"username\")\n                .str.count_match(r\"[a-zA-Z]\")\n                .cast(pl.Int64)\n                .alias(f\"{column}_num_of_letters\"),\n                pl.col(\"username\")\n                .str.count_match(r\"[^A-Za-z0-9]\")\n                .cast(pl.Int64)\n                .alias(f\"{column}_num_of_special_chars\"),\n                pl.col(\"username\")\n                .apply(EmailTransformer.__num_of_repeated_characters)\n                .alias(f\"{column}_num_of_repeated_chars\"),\n                (pl.col(\"username\").str.count_match(r\"[.\\-_]\") + 1)\n                .cast(pl.Int64)\n                .alias(f\"{column}_num_of_words\"),\n            ]\n\n            X = X.with_columns(expr).drop(column).rename({\"username\": column})\n        return X.to_pandas()\n\n    @staticmethod\n    def __num_of_repeated_characters(string: str) -&gt; int:  # pragma: no cover\n        return max(len(\"\".join(g)) for _, g in itertools.groupby(string))\n</code></pre>"},{"location":"API-reference/transformer/string_transformer/#sk_transformers.string_transformer.EmailTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Transforms the one column from X, containing the email addresses, into multiple columns.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pandas.DataFrame</code>  <p>DataFrame to transform.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pandas.DataFrame: Transformed dataframe containing the extra columns.</p>     Source code in <code>src/sk_transformers/string_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Transforms the one column from X, containing the email addresses,\n    into multiple columns.\n\n    Args:\n        X (pandas.DataFrame): DataFrame to transform.\n\n    Returns:\n        pandas.DataFrame: Transformed dataframe containing the extra columns.\n    \"\"\"\n    X = check_ready_to_transform(self, X, self.features, return_polars=True)\n\n    for column in self.features:  # pylint: disable=duplicate-code\n        X = X.with_columns(\n            pl.col(column)\n            .str.split_exact(\"@\", 1)\n            .struct.rename_fields([\"username\", \"domain\"])\n            .alias(\"email_parts\"),\n        ).unnest(\"email_parts\")\n\n        X = (\n            X.with_columns(\n                pl.col(\"domain\")\n                .str.split_exact(\".\", 1)\n                .struct.rename_fields([f\"{column}_domain\", \"subdomain\"])\n                .alias(\"domain_parts\"),\n            )\n            .unnest(\"domain_parts\")\n            .drop([\"domain\", \"subdomain\"])\n        )\n\n        expr = [\n            pl.col(\"username\")\n            .str.count_match(r\"\\d\")\n            .cast(pl.Int64)\n            .alias(f\"{column}_num_of_digits\"),\n            pl.col(\"username\")\n            .str.count_match(r\"[a-zA-Z]\")\n            .cast(pl.Int64)\n            .alias(f\"{column}_num_of_letters\"),\n            pl.col(\"username\")\n            .str.count_match(r\"[^A-Za-z0-9]\")\n            .cast(pl.Int64)\n            .alias(f\"{column}_num_of_special_chars\"),\n            pl.col(\"username\")\n            .apply(EmailTransformer.__num_of_repeated_characters)\n            .alias(f\"{column}_num_of_repeated_chars\"),\n            (pl.col(\"username\").str.count_match(r\"[.\\-_]\") + 1)\n            .cast(pl.Int64)\n            .alias(f\"{column}_num_of_words\"),\n        ]\n\n        X = X.with_columns(expr).drop(column).rename({\"username\": column})\n    return X.to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/string_transformer/#sk_transformers.string_transformer.IPAddressEncoderTransformer","title":"<code>IPAddressEncoderTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>Encodes IPv4 and IPv6 strings addresses to a float representation. To shrink the values to a reasonable size IPv4 addresses are divided by 2^10 and IPv6 addresses are divided by 2^48. Those values can be changed using the <code>ip4_divisor</code> and <code>ip6_divisor</code> parameters.</p> <p>Example: <pre><code>import pandas as pd\nfrom sk_transformers import IPAddressEncoderTransformer\n\nX = pd.DataFrame({\"foo\": [\"192.168.1.1\", \"2001:0db8:3c4d:0015:0000:0000:1a2f:1a2b\"]})\ntransformer = IPAddressEncoderTransformer([\"foo\"])\ntransformer.fit_transform(X)\n</code></pre> <pre><code>            foo\n0  3.232236e-01\n1  4.254077e-11\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>features</code>  <code>List[str]</code>  <p>List of features which should be transformed.</p>  required    <code>ip4_divisor</code>  <code>float</code>  <p>Divisor for IPv4 addresses.</p>  <code>10000000000.0</code>    <code>ip6_divisor</code>  <code>float</code>  <p>Divisor for IPv6 addresses.</p>  <code>1e+48</code>    <code>error_value</code>  <code>Union[int, float]</code>  <p>Value if parsing fails.</p>  <code>-999</code>      Source code in <code>src/sk_transformers/string_transformer.py</code> <pre><code>class IPAddressEncoderTransformer(BaseTransformer):\n    \"\"\"Encodes IPv4 and IPv6 strings addresses to a float representation. To\n    shrink the values to a reasonable size IPv4 addresses are divided by 2^10\n    and IPv6 addresses are divided by 2^48. Those values can be changed using\n    the `ip4_divisor` and `ip6_divisor` parameters.\n\n    Example:\n    ```python\n    import pandas as pd\n    from sk_transformers import IPAddressEncoderTransformer\n\n    X = pd.DataFrame({\"foo\": [\"192.168.1.1\", \"2001:0db8:3c4d:0015:0000:0000:1a2f:1a2b\"]})\n    transformer = IPAddressEncoderTransformer([\"foo\"])\n    transformer.fit_transform(X)\n    ```\n    ```\n                foo\n    0  3.232236e-01\n    1  4.254077e-11\n    ```\n\n    Args:\n        features (List[str]): List of features which should be transformed.\n        ip4_divisor (float): Divisor for IPv4 addresses.\n        ip6_divisor (float): Divisor for IPv6 addresses.\n        error_value (Union[int, float]): Value if parsing fails.\n    \"\"\"\n\n    def __init__(\n        self,\n        features: List[str],\n        ip4_divisor: float = 1e10,\n        ip6_divisor: float = 1e48,\n        error_value: Union[int, float] = -999,\n    ) -&gt; None:\n        super().__init__()\n        self.features = features\n        self.ip4_divisor = ip4_divisor\n        self.ip6_divisor = ip6_divisor\n        self.error_value = error_value\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Transforms the column containing the IP addresses to float column.\n\n        Args:\n            X (pandas.DataFrame): DataFrame to transform.\n\n        Returns:\n            pandas.DataFrame: Transformed dataframe.\n        \"\"\"\n        X = check_ready_to_transform(self, X, self.features, return_polars=True)\n\n        function = functools.partial(\n            IPAddressEncoderTransformer.__ip_to_float,\n            self.ip4_divisor,\n            self.ip6_divisor,\n            self.error_value,\n        )\n\n        return X.with_columns(\n            [pl.col(column).map(function) for column in self.features]\n        ).to_pandas()\n\n    @staticmethod\n    def __ip_to_float(\n        ip4_devisor: float,\n        ip6_devisor: float,\n        error_value: Union[int, float],\n        ip_address: pl.Series,\n    ) -&gt; pl.Series:  # pragma: no cover\n        ip_df = pl.DataFrame({\"ip_addresses\": ip_address})\n        ip_df = ip_df.with_columns(\n            [\n                pl.when(ip_address.str.contains(r\"^(?:\\d{1,3}\\.){3}\\d{1,3}$\"))\n                .then(ip_address)\n                .otherwise(\"0.0.0.0\")  # nosec\n                .alias(\"ipv4\"),\n                pl.when(\n                    ip_address.str.contains(r\"^([0-9A-Fa-f]{1,4}:){7}[0-9A-Fa-f]{1,4}$\")\n                )\n                .then(ip_address)\n                .otherwise(\"0:0:0:0:0:0:0:0\")\n                .alias(\"ipv6\"),\n            ]\n        )\n\n        ip_series_v4 = ip_df[\"ipv4\"]\n        octets = ip_series_v4.str.split(\".\")\n\n        ip_float_v4 = pl.Series(np.zeros(ip_address.shape[0]))\n        for i in range(4):\n            factor_v4 = 256 ** (3 - i) / ip4_devisor\n            ip_float_v4 += (\n                octets.arr.slice(i, 1).arr.explode().cast(pl.UInt32) * factor_v4\n            )\n\n        ip_series_v6 = ip_df[\"ipv6\"]\n        hextets = ip_series_v6.str.split(\":\")\n\n        ip_float_v6 = pl.Series(np.zeros(ip_address.shape[0]))\n        for i in range(8):\n            factor_v6 = 65536 ** (7 - i) / ip6_devisor\n            ip_float_v6 += (\n                hextets.arr.slice(i, 1).arr.explode().apply(lambda x: int(x, 16))\n                * factor_v6\n            )\n\n        return (ip_float_v4 + ip_float_v6).map_dict(\n            {0: error_value}, default=pl.first()\n        )\n</code></pre>"},{"location":"API-reference/transformer/string_transformer/#sk_transformers.string_transformer.IPAddressEncoderTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Transforms the column containing the IP addresses to float column.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pandas.DataFrame</code>  <p>DataFrame to transform.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pandas.DataFrame: Transformed dataframe.</p>     Source code in <code>src/sk_transformers/string_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Transforms the column containing the IP addresses to float column.\n\n    Args:\n        X (pandas.DataFrame): DataFrame to transform.\n\n    Returns:\n        pandas.DataFrame: Transformed dataframe.\n    \"\"\"\n    X = check_ready_to_transform(self, X, self.features, return_polars=True)\n\n    function = functools.partial(\n        IPAddressEncoderTransformer.__ip_to_float,\n        self.ip4_divisor,\n        self.ip6_divisor,\n        self.error_value,\n    )\n\n    return X.with_columns(\n        [pl.col(column).map(function) for column in self.features]\n    ).to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/string_transformer/#sk_transformers.string_transformer.PhoneTransformer","title":"<code>PhoneTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>Transforms a phone number into multiple features.</p> <p>Example: <pre><code>import pandas as pd\nfrom sk_transformers import PhoneTransformer\n\nX = pd.DataFrame({\"foo\": [\"+49123456789\", \"0044987654321\", \"3167891234\"]})\ntransformer = PhoneTransformer([\"foo\"])\ntransformer.fit_transform(X)\n</code></pre> <pre><code>             foo  foo_national_number  foo_country_code\n0   +49123456789             0.123457              0.49\n1  0044987654321             0.987654              0.44\n2     3167891234          -999.000000           -999.00\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>features</code>  <code>List[str]</code>  <p>List of features which should be transformed.</p>  required    <code>national_number_divisor</code>  <code>float</code>  <p>Divider <code>national_number</code>.</p>  <code>1000000000.0</code>    <code>country_code_divisor</code>  <code>flat</code>  <p>Divider for <code>country_code</code>.</p>  <code>100.0</code>    <code>error_value</code>  <code>str</code>  <p>Value to use if the phone number is invalid or the parsing fails.</p>  <code>'-999'</code>      Source code in <code>src/sk_transformers/string_transformer.py</code> <pre><code>class PhoneTransformer(BaseTransformer):\n    \"\"\"Transforms a phone number into multiple features.\n\n    Example:\n    ```python\n    import pandas as pd\n    from sk_transformers import PhoneTransformer\n\n    X = pd.DataFrame({\"foo\": [\"+49123456789\", \"0044987654321\", \"3167891234\"]})\n    transformer = PhoneTransformer([\"foo\"])\n    transformer.fit_transform(X)\n    ```\n    ```\n                 foo  foo_national_number  foo_country_code\n    0   +49123456789             0.123457              0.49\n    1  0044987654321             0.987654              0.44\n    2     3167891234          -999.000000           -999.00\n    ```\n\n    Args:\n        features (List[str]): List of features which should be transformed.\n        national_number_divisor (float): Divider `national_number`.\n        country_code_divisor (flat): Divider for `country_code`.\n        error_value (str): Value to use if the phone number is invalid or the parsing fails.\n    \"\"\"\n\n    def __init__(\n        self,\n        features: List[str],\n        national_number_divisor: float = 1e9,\n        country_code_divisor: float = 1e2,\n        error_value: str = \"-999\",\n    ) -&gt; None:\n        super().__init__()\n        self.features = features\n        self.national_number_divisor = national_number_divisor\n        self.country_code_divisor = country_code_divisor\n        self.error_value = error_value\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Calculates the similarity of two strings provided in `features`.\n\n        Args:\n            X (pandas.DataFrame): DataFrame to transform.\n\n        Returns:\n            pandas.DataFrame: Original dataframe containing the extra column with the calculated similarity.\n        \"\"\"\n        X = check_ready_to_transform(self, X, self.features, return_polars=True)\n\n        function_list: List[Callable] = [\n            lambda x: PhoneTransformer.__phone_to_float(\n                \"national_number\",\n                x,\n                int(self.national_number_divisor),\n                self.error_value,\n            ),\n            lambda x: PhoneTransformer.__phone_to_float(\n                \"country_code\", x, int(self.country_code_divisor), self.error_value\n            ),\n        ]\n\n        phone_number_attr_list: List[str] = [\"national_number\", \"country_code\"]\n\n        return X.with_columns(\n            [\n                pl.col(column).apply(function).alias(f\"{column}_{phone_number_attr}\")\n                for column in self.features\n                for function, phone_number_attr in zip(\n                    function_list, phone_number_attr_list\n                )\n            ]\n        ).to_pandas()\n\n    @staticmethod\n    def __phone_to_float(\n        attribute: str, phone: str, divisor: int, error_value: str\n    ) -&gt; float:  # pragma: no cover\n        phone = phone.replace(\" \", \"\")\n        phone = re.sub(r\"[^0-9+-]\", \"\", phone)\n        phone = re.sub(r\"^00\", \"+\", phone)\n        try:\n            return float(getattr(phonenumbers.parse(phone, None), attribute)) / divisor\n        except:  # pylint: disable=W0702\n            try:\n                return float(re.sub(r\"(?&lt;!^)[^0-9]\", \"\", error_value))\n            except:  # pylint: disable=W0702\n                return float(error_value)\n</code></pre>"},{"location":"API-reference/transformer/string_transformer/#sk_transformers.string_transformer.PhoneTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Calculates the similarity of two strings provided in <code>features</code>.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pandas.DataFrame</code>  <p>DataFrame to transform.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pandas.DataFrame: Original dataframe containing the extra column with the calculated similarity.</p>     Source code in <code>src/sk_transformers/string_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Calculates the similarity of two strings provided in `features`.\n\n    Args:\n        X (pandas.DataFrame): DataFrame to transform.\n\n    Returns:\n        pandas.DataFrame: Original dataframe containing the extra column with the calculated similarity.\n    \"\"\"\n    X = check_ready_to_transform(self, X, self.features, return_polars=True)\n\n    function_list: List[Callable] = [\n        lambda x: PhoneTransformer.__phone_to_float(\n            \"national_number\",\n            x,\n            int(self.national_number_divisor),\n            self.error_value,\n        ),\n        lambda x: PhoneTransformer.__phone_to_float(\n            \"country_code\", x, int(self.country_code_divisor), self.error_value\n        ),\n    ]\n\n    phone_number_attr_list: List[str] = [\"national_number\", \"country_code\"]\n\n    return X.with_columns(\n        [\n            pl.col(column).apply(function).alias(f\"{column}_{phone_number_attr}\")\n            for column in self.features\n            for function, phone_number_attr in zip(\n                function_list, phone_number_attr_list\n            )\n        ]\n    ).to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/string_transformer/#sk_transformers.string_transformer.StringCombinationTransformer","title":"<code>StringCombinationTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>Concatenates two string columns with a separator in between, but the concatenated strings are in alphabetical order. This is useful to get combinations of two strings regardless of the columns they belong in. For example, a place <code>A</code> in a <code>departure</code> column, and a place <code>B</code> in a <code>arrival</code> column and vice verse would both be treated as a <code>AB</code> in a new <code>route</code> column.</p> <p>Example: <pre><code>import pandas as pd\nfrom sk_transformers import StringCombinationTransformer\n\nX = pd.DataFrame({\"foo\": [\"a\", \"b\", \"c\"], \"bar\": [\"b\", \"a\", \"a\"]})\ntransformer = StringCombinationTransformer([(\"foo\", \"bar\", \"_\")])\ntransformer.fit_transform(X)\n</code></pre> <pre><code>  foo bar foo_bar_combi\n0   a   b           a_b\n1   b   a           a_b\n2   c   a           a_c\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>features</code>  <code>List[Tuple[str, str, str]]</code>  <p>A list of tuples containing the names of the two columns to be concatenated along with the separator.</p>  required      Source code in <code>src/sk_transformers/string_transformer.py</code> <pre><code>class StringCombinationTransformer(BaseTransformer):\n    \"\"\"Concatenates two string columns with a separator in between, but the\n    concatenated strings are in alphabetical order. This is useful to get\n    combinations of two strings regardless of the columns they belong in. For\n    example, a place `A` in a `departure` column, and a place `B` in a\n    `arrival` column and vice verse would both be treated as a `AB` in a new\n    `route` column.\n\n    Example:\n    ```python\n    import pandas as pd\n    from sk_transformers import StringCombinationTransformer\n\n    X = pd.DataFrame({\"foo\": [\"a\", \"b\", \"c\"], \"bar\": [\"b\", \"a\", \"a\"]})\n    transformer = StringCombinationTransformer([(\"foo\", \"bar\", \"_\")])\n    transformer.fit_transform(X)\n    ```\n    ```\n      foo bar foo_bar_combi\n    0   a   b           a_b\n    1   b   a           a_b\n    2   c   a           a_c\n    ```\n\n    Args:\n        features (List[Tuple[str, str, str]]): A list of tuples containing the names of the two columns to be\n            concatenated along with the separator.\n    \"\"\"\n\n    def __init__(self, features: List[Tuple[str, str, str]]) -&gt; None:\n        super().__init__()  # pylint: disable=duplicate-code\n        self.features = features\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Contatenates two string columns after ordering them alphabetically\n        first.\n\n        Args:\n            X (pandas.DataFrame): DataFrame to transform.\n\n        Returns:\n            pandas.DataFrame: Dataframe containing the additional columns.\n        \"\"\"\n        X = check_ready_to_transform(\n            self,\n            X,\n            [feature[i] for feature in self.features for i in [0, 1]],\n        )\n\n        for column1, column2, separator in self.features:\n            X[f\"{column1}_{column2}_combi\"] = (X[column1] &lt; X[column2]) * (\n                X[column1] + separator + X[column2]\n            ) + (X[column1] &gt;= X[column2]) * (X[column2] + separator + X[column1])\n\n        return X\n</code></pre>"},{"location":"API-reference/transformer/string_transformer/#sk_transformers.string_transformer.StringCombinationTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Contatenates two string columns after ordering them alphabetically first.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pandas.DataFrame</code>  <p>DataFrame to transform.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pandas.DataFrame: Dataframe containing the additional columns.</p>     Source code in <code>src/sk_transformers/string_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Contatenates two string columns after ordering them alphabetically\n    first.\n\n    Args:\n        X (pandas.DataFrame): DataFrame to transform.\n\n    Returns:\n        pandas.DataFrame: Dataframe containing the additional columns.\n    \"\"\"\n    X = check_ready_to_transform(\n        self,\n        X,\n        [feature[i] for feature in self.features for i in [0, 1]],\n    )\n\n    for column1, column2, separator in self.features:\n        X[f\"{column1}_{column2}_combi\"] = (X[column1] &lt; X[column2]) * (\n            X[column1] + separator + X[column2]\n        ) + (X[column1] &gt;= X[column2]) * (X[column2] + separator + X[column1])\n\n    return X\n</code></pre>"},{"location":"API-reference/transformer/string_transformer/#sk_transformers.string_transformer.StringSimilarityTransformer","title":"<code>StringSimilarityTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>Calculates the similarity between two strings using the <code>gestalt pattern matching</code> algorithm from the <code>SequenceMatcher</code> class.</p> <p>Example: <pre><code>import pandas as pd\nfrom sk_transformers import StringSimilarityTransformer\n\nX = pd.DataFrame(\n    {\n        \"foo\": [\"abcdefgh\", \"ijklmnop\", \"qrstuvwx\"],\n        \"bar\": [\"ghabcdef\", \"ijklmnop\", \"qr000000\"],\n    }\n)\ntransformer = StringSimilarityTransformer((\"foo\", \"bar\"))\ntransformer.fit_transform(X)\n</code></pre> <pre><code>        foo       bar  foo_bar_similarity\n0  abcdefgh  ghabcdef                0.75\n1  ijklmnop  ijklmnop                1.00\n2  qrstuvwx  qr000000                0.25\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>features</code>  <code>Tuple[str, str]</code>  <p>The two columns that contain the strings for which the similarity should be calculated.</p>  required      Source code in <code>src/sk_transformers/string_transformer.py</code> <pre><code>class StringSimilarityTransformer(BaseTransformer):\n    \"\"\"Calculates the similarity between two strings using the `gestalt pattern\n    matching` algorithm from the `SequenceMatcher` class.\n\n    Example:\n    ```python\n    import pandas as pd\n    from sk_transformers import StringSimilarityTransformer\n\n    X = pd.DataFrame(\n        {\n            \"foo\": [\"abcdefgh\", \"ijklmnop\", \"qrstuvwx\"],\n            \"bar\": [\"ghabcdef\", \"ijklmnop\", \"qr000000\"],\n        }\n    )\n    transformer = StringSimilarityTransformer((\"foo\", \"bar\"))\n    transformer.fit_transform(X)\n    ```\n    ```\n            foo       bar  foo_bar_similarity\n    0  abcdefgh  ghabcdef                0.75\n    1  ijklmnop  ijklmnop                1.00\n    2  qrstuvwx  qr000000                0.25\n    ```\n\n    Args:\n        features (Tuple[str, str]): The two columns that contain the strings for which the similarity should be calculated.\n    \"\"\"\n\n    def __init__(self, features: Tuple[str, str]) -&gt; None:\n        super().__init__()\n        self.features = features\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Calculates the similarity of two strings provided in `features`.\n\n        Args:\n            X (pandas.DataFrame): DataFrame to transform.\n\n        Returns:\n            pandas.DataFrame: Original dataframe containing the extra column with the calculated similarity.\n        \"\"\"\n        X = check_ready_to_transform(self, X, list(self.features), return_polars=True)\n\n        return X.with_columns(\n            pl.struct(\n                [\n                    pl.col(self.features[0]).str.strip().str.to_lowercase(),\n                    pl.col(self.features[1]).str.strip().str.to_lowercase(),\n                ]\n            )\n            .apply(\n                lambda x: SequenceMatcher(\n                    None,\n                    unicodedata.normalize(\"NFKD\", x[self.features[0]])\n                    .encode(\"utf8\", \"strict\")\n                    .decode(\"utf8\"),\n                    unicodedata.normalize(\"NFKD\", x[self.features[1]])\n                    .encode(\"utf8\", \"strict\")\n                    .decode(\"utf8\"),\n                ).ratio()\n            )\n            .alias(f\"{self.features[0]}_{self.features[1]}_similarity\")\n        ).to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/string_transformer/#sk_transformers.string_transformer.StringSimilarityTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Calculates the similarity of two strings provided in <code>features</code>.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pandas.DataFrame</code>  <p>DataFrame to transform.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pandas.DataFrame: Original dataframe containing the extra column with the calculated similarity.</p>     Source code in <code>src/sk_transformers/string_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Calculates the similarity of two strings provided in `features`.\n\n    Args:\n        X (pandas.DataFrame): DataFrame to transform.\n\n    Returns:\n        pandas.DataFrame: Original dataframe containing the extra column with the calculated similarity.\n    \"\"\"\n    X = check_ready_to_transform(self, X, list(self.features), return_polars=True)\n\n    return X.with_columns(\n        pl.struct(\n            [\n                pl.col(self.features[0]).str.strip().str.to_lowercase(),\n                pl.col(self.features[1]).str.strip().str.to_lowercase(),\n            ]\n        )\n        .apply(\n            lambda x: SequenceMatcher(\n                None,\n                unicodedata.normalize(\"NFKD\", x[self.features[0]])\n                .encode(\"utf8\", \"strict\")\n                .decode(\"utf8\"),\n                unicodedata.normalize(\"NFKD\", x[self.features[1]])\n                .encode(\"utf8\", \"strict\")\n                .decode(\"utf8\"),\n            ).ratio()\n        )\n        .alias(f\"{self.features[0]}_{self.features[1]}_similarity\")\n    ).to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/string_transformer/#sk_transformers.string_transformer.StringSlicerTransformer","title":"<code>StringSlicerTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>Slices all entries of specified string features using the <code>slice()</code> function.</p> <p>Note: The arguments for the <code>slice()</code> function are passed as a tuple. This shares the python quirk of writing a tuple with a single argument with the trailing comma.</p> <p>Example: <pre><code>import pandas as pd\nfrom sk_transformers import StringSlicerTransformer\n\nX = pd.DataFrame({\"foo\": [\"abc\", \"def\", \"ghi\"], \"bar\": [\"jkl\", \"mno\", \"pqr\"]})\ntransformer = StringSlicerTransformer([(\"foo\", (1, 3)), (\"bar\", (2,))])\ntransformer.fit_transform(X)\n</code></pre> <pre><code>   foo  bar foo_slice bar_slice\n0  abc  jkl        bc        jk\n1  def  mno        ef        mn\n2  ghi  pqr        hi        pq\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>features</code>  <code>List[Tuple[str, Union[Tuple[int], Tuple[int, int], Tuple[int, int, int]], Optional[str]]]</code>  <p>The arguments to the <code>slice</code> function, for each feature.</p>  required      Source code in <code>src/sk_transformers/string_transformer.py</code> <pre><code>class StringSlicerTransformer(BaseTransformer):\n    \"\"\"Slices all entries of specified string features using the `slice()`\n    function.\n\n    Note: The arguments for the `slice()` function are passed as a tuple. This shares\n    the python quirk of writing a tuple with a single argument with the trailing comma.\n\n    Example:\n    ```python\n    import pandas as pd\n    from sk_transformers import StringSlicerTransformer\n\n    X = pd.DataFrame({\"foo\": [\"abc\", \"def\", \"ghi\"], \"bar\": [\"jkl\", \"mno\", \"pqr\"]})\n    transformer = StringSlicerTransformer([(\"foo\", (1, 3)), (\"bar\", (2,))])\n    transformer.fit_transform(X)\n    ```\n    ```\n       foo  bar foo_slice bar_slice\n    0  abc  jkl        bc        jk\n    1  def  mno        ef        mn\n    2  ghi  pqr        hi        pq\n    ```\n\n    Args:\n        features (List[Tuple[str, Union[Tuple[int], Tuple[int, int], Tuple[int, int, int]], Optional[str]]]): The arguments to the `slice` function, for each feature.\n    \"\"\"\n\n    def __init__(\n        self,\n        features: List[\n            Tuple[\n                str,\n                Union[Tuple[int], Tuple[int, int], Tuple[int, int, int]],\n                Optional[str],\n            ]\n        ],\n    ) -&gt; None:\n        super().__init__()\n        self.features = features\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Slices the strings of specified features in the dataframe.\n\n        Args:\n            X (pandas.DataFrame): DataFrame to transform.\n\n        Returns:\n            pandas.DataFrame: Original dataframe with sliced strings in specified features.\n        \"\"\"\n        X = check_ready_to_transform(\n            self, X, [feature[0] for feature in self.features], return_polars=True\n        )\n\n        for slice_tuple in self.features:\n            column = slice_tuple[0]\n            slice_args = slice_tuple[1]\n            slice_column = slice_tuple[2] if len(slice_tuple) == 3 else column\n\n            slice_offset = slice_args[0] if len(slice_args) &gt; 1 else 0\n            slice_length = (\n                (slice_args[1] - slice_args[0])  # type: ignore[misc]\n                if len(slice_args) &gt; 1\n                else slice_args[0]\n            )\n\n            if len(slice_args) == 3:\n                warnings.warn(\n                    \"StringSlicerTransformer currently does not support increments.\\n Only the first two elements of the slice tuple will be considered.\"\n                )\n\n            X = X.with_columns(\n                pl.col(column)\n                .str.slice(offset=slice_offset, length=slice_length)\n                .alias(slice_column)  # type: ignore[arg-type]\n            )\n        return X.to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/string_transformer/#sk_transformers.string_transformer.StringSlicerTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Slices the strings of specified features in the dataframe.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pandas.DataFrame</code>  <p>DataFrame to transform.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pandas.DataFrame: Original dataframe with sliced strings in specified features.</p>     Source code in <code>src/sk_transformers/string_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Slices the strings of specified features in the dataframe.\n\n    Args:\n        X (pandas.DataFrame): DataFrame to transform.\n\n    Returns:\n        pandas.DataFrame: Original dataframe with sliced strings in specified features.\n    \"\"\"\n    X = check_ready_to_transform(\n        self, X, [feature[0] for feature in self.features], return_polars=True\n    )\n\n    for slice_tuple in self.features:\n        column = slice_tuple[0]\n        slice_args = slice_tuple[1]\n        slice_column = slice_tuple[2] if len(slice_tuple) == 3 else column\n\n        slice_offset = slice_args[0] if len(slice_args) &gt; 1 else 0\n        slice_length = (\n            (slice_args[1] - slice_args[0])  # type: ignore[misc]\n            if len(slice_args) &gt; 1\n            else slice_args[0]\n        )\n\n        if len(slice_args) == 3:\n            warnings.warn(\n                \"StringSlicerTransformer currently does not support increments.\\n Only the first two elements of the slice tuple will be considered.\"\n            )\n\n        X = X.with_columns(\n            pl.col(column)\n            .str.slice(offset=slice_offset, length=slice_length)\n            .alias(slice_column)  # type: ignore[arg-type]\n        )\n    return X.to_pandas()\n</code></pre>"},{"location":"API-reference/transformer/string_transformer/#sk_transformers.string_transformer.StringSplitterTransformer","title":"<code>StringSplitterTransformer</code>","text":"<p>         Bases: <code>BaseTransformer</code></p> <p>Uses the pandas <code>str.split</code> method to split a column of strings into multiple columns.</p> <p>Example: <pre><code>import pandas as pd\nfrom sk_transformers import StringSplitterTransformer\n\nX = pd.DataFrame({\"foo\": [\"a_b\", \"c_d\", \"e_f\"], \"bar\": [\"g*h*i\", \"j*k*l\", \"m*n*o\"]})\ntransformer = StringSplitterTransformer([(\"foo\", \"_\", 2), (\"bar\", \"*\", 3)])\ntransformer.fit_transform(X)\n</code></pre> <pre><code>   foo    bar foo_part_1 foo_part_2 bar_part_1 bar_part_2 bar_part_3\n0  a_b  g*h*i          a          b          g          h          i\n1  c_d  j*k*l          c          d          j          k          l\n2  e_f  m*n*o          e          f          m          n          o\n</code></pre></p> <p>Parameters:</p>    Name Type Description Default     <code>features</code>  <code>List[Tuple[str, str, Optional[int]]]</code>  <p>A list of tuples where the first element is the name of the feature, the second element is the string separator, and a third optional element is the desired number of splits. If the third element is not provided or is equal to 0 or -1, maximum number of splits are made.</p>  required      Source code in <code>src/sk_transformers/string_transformer.py</code> <pre><code>class StringSplitterTransformer(BaseTransformer):\n    \"\"\"Uses the pandas `str.split` method to split a column of strings into\n    multiple columns.\n\n    Example:\n    ```python\n    import pandas as pd\n    from sk_transformers import StringSplitterTransformer\n\n    X = pd.DataFrame({\"foo\": [\"a_b\", \"c_d\", \"e_f\"], \"bar\": [\"g*h*i\", \"j*k*l\", \"m*n*o\"]})\n    transformer = StringSplitterTransformer([(\"foo\", \"_\", 2), (\"bar\", \"*\", 3)])\n    transformer.fit_transform(X)\n    ```\n    ```\n       foo    bar foo_part_1 foo_part_2 bar_part_1 bar_part_2 bar_part_3\n    0  a_b  g*h*i          a          b          g          h          i\n    1  c_d  j*k*l          c          d          j          k          l\n    2  e_f  m*n*o          e          f          m          n          o\n    ```\n\n    Args:\n        features (List[Tuple[str, str, Optional[int]]]): A list of tuples where\n            the first element is the name of the feature,\n            the second element is the string separator,\n            and a third optional element is the desired number of splits.\n            If the third element is not provided or is equal to 0 or -1, maximum number of splits are made.\n    \"\"\"\n\n    def __init__(\n        self,\n        features: List[\n            Tuple[\n                str,\n                str,\n                int,\n            ]\n        ],\n    ) -&gt; None:\n        super().__init__()\n        self.features = [\n            (split_tuple[0], split_tuple[1], split_tuple[2])\n            if len(split_tuple) == 3\n            else (split_tuple[0], split_tuple[1], -1)\n            for split_tuple in features\n        ]\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Splits the strings based on a separator character.\n\n        Args:\n            X (pandas.DataFrame): DataFrame to transform.\n\n        Returns:\n            pandas.DataFrame: Dataframe containing additional columns containing\n                each split part of the string.\n        \"\"\"\n        X = check_ready_to_transform(\n            self, X, [feature[0] for feature in self.features], return_polars=True\n        )\n\n        max_possible_splits_list: List[int] = [\n            X[column].str.count_match(separator).max()  # type: ignore\n            for column, separator, _ in self.features\n        ]\n\n        select_with_expr = [\n            pl.col(column)\n            .str.splitn(by=separator, n=max_possible_split + 1)\n            .struct.rename_fields(\n                [column + f\"_part_{i}\" for i in range(1, max_possible_split + 2)]\n            )\n            .alias(column + \"_alias\")\n            if maxsplit in [0, -1] or maxsplit &gt; max_possible_split\n            else (\n                pl.col(column)\n                .str.splitn(by=separator, n=maxsplit + 1)\n                .struct.rename_fields(\n                    [column + f\"_part_{i}\" for i in range(1, maxsplit + 2)]\n                )\n                .alias(column + \"_alias\")\n            )\n            for (column, separator, maxsplit), max_possible_split in zip(\n                self.features, max_possible_splits_list\n            )\n        ]\n\n        return (\n            X.with_columns(select_with_expr)\n            .unnest([column + \"_alias\" for column, _, _ in self.features])\n            .to_pandas()\n        )\n</code></pre>"},{"location":"API-reference/transformer/string_transformer/#sk_transformers.string_transformer.StringSplitterTransformer.transform","title":"<code>transform(X)</code>","text":"<p>Splits the strings based on a separator character.</p> <p>Parameters:</p>    Name Type Description Default     <code>X</code>  <code>pandas.DataFrame</code>  <p>DataFrame to transform.</p>  required     <p>Returns:</p>    Type Description      <code>pd.DataFrame</code>  <p>pandas.DataFrame: Dataframe containing additional columns containing each split part of the string.</p>     Source code in <code>src/sk_transformers/string_transformer.py</code> <pre><code>def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Splits the strings based on a separator character.\n\n    Args:\n        X (pandas.DataFrame): DataFrame to transform.\n\n    Returns:\n        pandas.DataFrame: Dataframe containing additional columns containing\n            each split part of the string.\n    \"\"\"\n    X = check_ready_to_transform(\n        self, X, [feature[0] for feature in self.features], return_polars=True\n    )\n\n    max_possible_splits_list: List[int] = [\n        X[column].str.count_match(separator).max()  # type: ignore\n        for column, separator, _ in self.features\n    ]\n\n    select_with_expr = [\n        pl.col(column)\n        .str.splitn(by=separator, n=max_possible_split + 1)\n        .struct.rename_fields(\n            [column + f\"_part_{i}\" for i in range(1, max_possible_split + 2)]\n        )\n        .alias(column + \"_alias\")\n        if maxsplit in [0, -1] or maxsplit &gt; max_possible_split\n        else (\n            pl.col(column)\n            .str.splitn(by=separator, n=maxsplit + 1)\n            .struct.rename_fields(\n                [column + f\"_part_{i}\" for i in range(1, maxsplit + 2)]\n            )\n            .alias(column + \"_alias\")\n        )\n        for (column, separator, maxsplit), max_possible_split in zip(\n            self.features, max_possible_splits_list\n        )\n    ]\n\n    return (\n        X.with_columns(select_with_expr)\n        .unnest([column + \"_alias\" for column, _, _ in self.features])\n        .to_pandas()\n    )\n</code></pre>"}]}